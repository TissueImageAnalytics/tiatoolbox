# ***** BEGIN GPL LICENSE BLOCK *****
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
#
# The Original Code is Copyright (C) 2020, TIALab, University of Warwick
# All rights reserved.
# ***** END GPL LICENSE BLOCK *****

"""This module enables patch-level prediction."""

import math
import tqdm
import numpy as np
import PIL
import requests
import pathlib
import torch
import torch.nn as nn
import torchvision.transforms as transforms

from tiatoolbox.models.abc import Model_Base
from tiatoolbox.models.backbone import get_model
from tiatoolbox.models.dataset import Patch_Dataset


class CNN_Patch_Model(Model_Base):
    """Extends the backbone model so that is performs classification
    at the output of the network.

    Attributes:
        nr_classes (int): number of classes output by the model.
        feat_extract (nn.Module): backbone CNN model.
        pool (nn.Module): type of pooling applied after feature extraction.
        classifier (nn.Module): linear classifier module used to map the features
                                to the output.

    """

    def __init__(self, backbone, nr_input_ch=3, nr_classes=1):
        super().__init__()
        self.nr_classes = nr_classes

        self.feat_extract = get_model(backbone)
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        #! TODO: remove hard-coding of 512 channels below @ Dang
        self.classifer = nn.Linear(512, nr_classes)

    def forward(self, imgs):
        feat = self.feat_extract(imgs)
        gap_feat = self.pool(feat)
        gap_feat = torch.flatten(gap_feat, 1)
        logit = self.classifer(gap_feat)
        prob = torch.softmax(logit, -1)
        return prob

    @staticmethod
    def infer_batch(model, batch_data):
        """Run inference on an input batch. Contains logic for
        forward operation as well as i/o aggregation.

        Args:
            model (nn.Module): PyTorch defined model.
            batch_data (ndarray): a batch of data generated by torch.utils.data.DataLoader.

        """
        img_patches = batch_data
        img_patches_gpu = img_patches.to("cuda").type(torch.float32)  # to NCHW
        img_patches_gpu = img_patches_gpu.permute(0, 3, 1, 2).contiguous()

        # inference mode
        model.eval()
        # dont compute the gradient (not training)
        with torch.no_grad():
            output = model(img_patches_gpu)
        # output should be a single tensor or scalar
        return output.cpu().numpy()


class CNN_Patch_Predictor(object):
    """Patch-level predictor.

    Attributes:
        batch_size (int): number of images fed into the model each time.
        nr_input_ch (int): number of input channels of the image. If RGB, then this is 3.
        nr_loader_worker (int): number of workers used in torch.utils.data.DataLoader.
        verbose (bool): whether to output logging information.
        model (nn.Module): Defined PyTorch model.

    Usage:
        >>> image_list = np.random.randint(0, 255, [4, 512, 512, 3])
        >>> model = CNN_Patch_Predictor('resnet50', nr_class=8, batch_size=4, nr_loader_workers=4)
        >>> model.predict(image_list)

    """

    def __init__(
        self,
        batch_size,
        model=None,
        pretrained_model=None,
        nr_input_ch=3,
        nr_classes=None,
        nr_loader_worker=0,
        model_dir='model_weights/'
        verbose=True,
        *args,
        **kwargs,
    ):
        """Initialise the Patch Predictor. Note, if model is supplied in the arguments, the it
        will override the backbone.

        Args:
            batch_size (int): number of images fed into the model each time.
            model (nn.Module): defined PyTorch model with the define backbone as the feature extractor.
            pretrained_model (str): name of the pretrained model used to process the data.
            nr_input_ch (int): number of input channels of the image. If RGB, then this is 3.
            nr_loader_worker (int): number of workers used in torch.utils.data.DataLoader.
            verbose (bool): whether to output logging information.

        """
        super().__init__()

        if model and pretrained_model:
            raise ValueError("Must only provide one of model or pretrained_model")

        #! first check to see whether model checkpoint path exists on server (if pretrained is not None)
        if pretrained_model:
            # do something
            # get backbone and dataset from string info
            pass

        if not pretrained:
            # get kwargs
            backbone = kwargs["backbone"]
            pretrained = kwargs["pretrained"]
            # etc etc :)

        # self.batch_size = batch_size
        # self.backbone = backbone
        # self.nr_input_ch = nr_input_ch
        # self.nr_loader_worker = nr_loader_worker
        # self.verbose = verbose

        self.model_dir = model_dir
        self.batch_size = batch_size
        nr_classes = 9
        backbone = "resnet18"
        self.backbone = backbone
        pretrained = "kather"
        self.nr_input_ch = nr_input_ch
        self.nr_loader_worker = nr_loader_worker
        self.verbose = verbose

        if model is not None:
            self.model = model
        else:
            # ! TODO: will provide the pretrained model for speicifc
            # ! checkpoint, so querry the # class from that @Dang
            self.model = CNN_Patch_Model(
                backbone, nr_input_ch=nr_input_ch, nr_classes=nr_classes
            )

        self.load_model(dataset=pretrained)
        return

    def load_model(self, model_path=None, dataset=None, *args, **kwargs):
        """Load model checkpoint either using a supplied model_path or
        by providing a supported dataset name for which the model has been
        trained on.

        Args:
            model_path (pathlib.Path) = path to checkpoint file.
            dataset (str) = name of dataset that the model has been trained on.

        """
        if model_path == None:
            dataset = dataset.lower()
            # download and save model weights
            #! TODO Decide where to dump models - ask Shan
            model_path = "%s/%s_%s.pth" % (self.model_dir, self.backbone, dataset)
            if not pathlib.Path(model_path).is_file():
                url_path = "%s%s_%s.pth" % (self.url_root, backbone, dataset)
                print("Downloading model weights from %s" % url_path)
                r = requests.get(url_path)
                with open(model_path, "wb") as f:
                    f.write(r.content)

        # ! assume to be saved in single GPU mode
        saved_state_dict = torch.load(model_path)
        self.model.load_state_dict(saved_state_dict, strict=True)
        return

    def predict(
        self, dataset, return_probs=False, return_labels=False, *args, **kwargs
    ):
        """Make a prediction on a dataset.

        Args:
            dataset (torch.utils.data.Dataset): PyTorch dataset object created using
                tiatoolbox.models.data.classification.Patch_Dataset.
            return_probs (bool): whether to return per-class model probabilities.
            return_labels (bool): whether to return the predicted class labels.

        Returns:
            output: predictions of the input dataset

        """

        # TODO preprocessing must be defined with the dataset
        dataloader = torch.utils.data.DataLoader(
            dataset,
            num_workers=self.nr_loader_worker,
            batch_size=self.batch_size,
            drop_last=False,
        )

        # !TODO: need to have a single protocol later for this
        pbar = tqdm.tqdm(
            total=int(len(dataloader)), leave=True, ncols=80, ascii=True, position=0
        )

        # ! may need to take into account CPU/GPU mode
        model = torch.nn.DataParallel(self.model)
        model = model.to("cuda")

        all_output = {}
        preds_output = []
        probs_output = []
        labels_output = []

        if return_labels and not dataset.return_label:
            # TODO use python warning!
            print(
                "WARNING: return_labels selected but dataset does not return any labels."
            )

        for batch_idx, batch_data in enumerate(dataloader):
            # calling the static method of that specific ModelDesc
            # on the an instance of ModelDesc, maybe there is a better way
            # to go about this
            if dataset.return_label:
                batch_input, batch_label = batch_data
            else:
                batch_input = batch_data
            batch_output_probs = self.model.infer_batch(model, batch_input)
            # get the index of the class with the maximum probability
            batch_output = np.argmax(batch_output_probs, axis=-1)
            preds_output.extend(batch_output.tolist())
            if return_probs:
                # return raw output
                probs_output.extend(batch_output_probs.tolist())
            if return_labels and dataset.return_label:
                # return class labels
                labels_output.extend(batch_label.numpy())

            # may be a with block + flag would be nicer
            if self.verbose:
                pbar.update()
        if self.verbose:
            pbar.close()

        pred_output = np.array(preds_output)

        #! use something like below @Dang - get class names by indexing with predictions
        # class_names = label_code[pred_output]

        all_output = {"preds": preds_output}
        if return_probs:
            all_output["probs"] = probs_output
        if return_labels:
            all_output["labels"] = labels_output

        return all_output


class Kather_CNN_Patch_Predictor(CNN_Patch_Predictor):
    def __init__():
        pass


def get_patch_predictor():
    pass
