# ***** BEGIN GPL LICENSE BLOCK *****
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
#
# The Original Code is Copyright (C) 2020, TIALab, University of Warwick
# All rights reserved.
# ***** END GPL LICENSE BLOCK *****

"""This module enables patch-level prediction."""

import math
import tqdm
import numpy as np
import PIL
import requests
import pathlib
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import os

from tiatoolbox import TIATOOLBOX_HOME
from tiatoolbox.models.abc import Model_Base
from tiatoolbox.models.backbone import get_model
from tiatoolbox.models.dataset import Patch_Dataset
from tiatoolbox.utils.misc import download_data

class CNN_Patch_Model(Model_Base):
    """Retrieve the model backbone and attach a new FCN ontop for new class
    to perform classification.

    Attributes:
        nr_classes (int): number of classes output by the model.
        feat_extract (nn.Module): backbone CNN model.
        pool (nn.Module): type of pooling applied after feature extraction.
        classifier (nn.Module): linear classifier module used to map the features
                                to the output.

    """

    def __init__(self, backbone, nr_input_ch=3, nr_classes=1):
        super().__init__()
        self.nr_classes = nr_classes

        self.feat_extract = get_model(backbone)
        self.pool = nn.AdaptiveAvgPool2d((1, 1))

        # best way to retrieve channel dynamically is passing a small forward
        prev_nr_ch = self.feat_extract(torch.rand([2,3,4,4])).shape[1]
        self.classifer = nn.Linear(prev_nr_ch, nr_classes)

    def forward(self, imgs):
        feat = self.feat_extract(imgs)
        gap_feat = self.pool(feat)
        gap_feat = torch.flatten(gap_feat, 1)
        logit = self.classifer(gap_feat)
        prob = torch.softmax(logit, -1)
        return prob

    @staticmethod
    def infer_batch(model, batch_data):
        """Run inference on an input batch. Contains logic for
        forward operation as well as i/o aggregation.

        Args:
            model (nn.Module): PyTorch defined model.
            batch_data (ndarray): a batch of data generated by torch.utils.data.DataLoader.

        """
        img_patches = batch_data
        img_patches_gpu = img_patches.to("cuda").type(torch.float32)  # to NCHW
        img_patches_gpu = img_patches_gpu.permute(0, 3, 1, 2).contiguous()

        # inference mode
        model.eval()
        # dont compute the gradient (not training)
        with torch.no_grad():
            output = model(img_patches_gpu)
        # output should be a single tensor or scalar
        return output.cpu().numpy()

class CNN_Patch_Predictor(object):
    """Patch-level predictor.

    Attributes:
        batch_size (int): number of images fed into the model each time.
        nr_input_ch (int): number of input channels of the image. If RGB, then this is 3.
        nr_loader_worker (int): number of workers used in torch.utils.data.DataLoader.
        verbose (bool): whether to output logging information.
        model (nn.Module): Defined PyTorch model.

    Usage:
        >>> image_list = np.random.randint(0, 255, [4, 512, 512, 3])
        >>> model = CNN_Patch_Predictor('resnet50', nr_class=8, batch_size=4, nr_loader_workers=4)
        >>> model.predict(image_list)

    """

    def __init__(
        self,
        batch_size=8,
        nr_loader_worker=0,
        model=None,
        predefined_model=None,
        pretrained_weight=None,
        verbose=True,
        *args,
        **kwargs,
    ):
        """Initialise the Patch Predictor. Note, if model is supplied in the arguments, the it
        will override the backbone.

        Args:
            model (nn.Module): use this externally defined PyTorch model for prediction. Default is `None`. 
                            Upon provided, `pretrained_model` argument is ignored, 

            predefined_model (str): name of the existing models support by tiatoolbox for processing the data. 
                                    Currently support.
                                    - resnet18#kather : resnet18 backbone trained on Kather dataset [URL] 

                                    By default, their pretrained weights will also be downloaded. However, you can 
                                    overload with your own set of weights via `pretrained_weight` argument.
                                    Argument is case insensitive

            pretrained_weight (str): path to the weight of one of the corresponding `predefined_model`.

            batch_size (int) : number of images fed into the model each time.
            nr_loader_worker (int) : number of workers to load the data. 
                                Take note that they will also perform preprocessing.
            verbose (bool): whether to output logging information.

        """
        super().__init__()

        if model is None and predefined_model is None:
            raise ValueError("Must provide either of `model` or `predefined_model`")

        if model is not None:
            self.model = model
        else:
            self.model = get_predefined_model(predefined_model, pretrained_weight)
        
        self.batch_size = batch_size
        self.nr_loader_worker = nr_loader_worker
        self.verbose = verbose
        return

    # ! @simon, remove return_labels till we can finalize where to go with it
    def predict(
        self, dataset, return_probs=False, on_gpu=True, *args, **kwargs
    ):
        """Make a prediction on a dataset.

        Args:
            dataset (torch.utils.data.Dataset): PyTorch dataset object created using
                tiatoolbox.models.data.classification.Patch_Dataset.
            return_probs (bool): whether to return per-class model probabilities.

        Returns:
            output: predictions of the input dataset

        """

        # TODO preprocessing must be defined with the dataset
        dataloader = torch.utils.data.DataLoader(
            dataset,
            num_workers=self.nr_loader_worker,
            batch_size=self.batch_size,
            drop_last=False,
        )

        # !TODO: need to have a single protocol later for this
        pbar = tqdm.tqdm(
            total=int(len(dataloader)), leave=True, ncols=80, ascii=True, position=0
        )

        # ! may need to take into account CPU/GPU mode
        model = torch.nn.DataParallel(self.model)
        if on_gpu:
            model = model.to("cuda")

        all_output = {}
        preds_output = []
        probs_output = []
        labels_output = []

        for batch_idx, batch_data in enumerate(dataloader):
            # calling the static method of that specific ModelDesc
            # on the an instance of ModelDesc, maybe there is a better way
            # to go about this
            if dataset.return_label:
                batch_input, batch_label = batch_data
            else:
                batch_input = batch_data

            batch_output_probs = self.model.infer_batch(model, batch_input)
            # get the index of the class with the maximum probability
            batch_output = np.argmax(batch_output_probs, axis=-1)
            preds_output.extend(batch_output.tolist())
            if return_probs:
                # return raw output
                probs_output.extend(batch_output_probs.tolist())

            # may be a with block + flag would be nicer
            if self.verbose:
                pbar.update()
        if self.verbose:
            pbar.close()

        pred_output = np.array(preds_output)

        #! use something like below @Dang - get class names by indexing with predictions
        # class_names = label_code[pred_output]

        all_output = {"preds": preds_output}
        if return_probs:
            all_output["probs"] = probs_output
        return all_output

__pretrained_model = {
    'resnet18#kather' : {
        'pretrained' : 'URL' , # ! path on server @simon
        'nr_input_ch' : 3,
        'nr_classes'  : 9
    }
}

def get_predefined_model(predefined_model=None, pretrained_weight=None):
    assert isinstance(predefined_model, str)
    # parsing protocol 
    predefined_model = predefined_model.lower()
    backbone, dataset = predefined_model.split('#')
    cfg = __pretrained_model[predefined_model]
    model = CNN_Patch_Model(backbone=backbone, 
                    nr_input_ch=cfg['nr_input_ch'],
                    nr_classes=cfg['nr_classes'])
    
    if pretrained_weight is None:
        pretrained_weight_url = cfg['pretrained']
        pretrained_weight = os.path.join(TIATOOLBOX_HOME, 'models/', )
        if not os.path.exists(pretrained_weight):
            download_data(pretrained_weight_url, pretrained_weight)
    # ! assume to be saved in single GPU mode
    saved_state_dict = torch.load(pretrained_weight)
    model.load_state_dict(saved_state_dict, strict=True)
    return model

