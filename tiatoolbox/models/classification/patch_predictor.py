# ***** BEGIN GPL LICENSE BLOCK *****
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
#
# The Original Code is Copyright (C) 2020, TIALab, University of Warwick
# All rights reserved.
# ***** END GPL LICENSE BLOCK *****

"""This module enables patch-level prediction."""

import math
import tqdm
import numpy as np
import PIL
import requests
import pathlib
import torch
import torch.nn as nn
import torchvision.transforms as transforms

from tiatoolbox.models.backbone import get_model
from tiatoolbox.models.dataset import Patch_Dataset, dataset_info, preproc_info


class CNN_Patch_Model(nn.Module):
    """Extends the backbone model so that is performs classification
    at the output of the network.

    Attributes:
        nr_classes (int): number of classes output by the model.
        feat_extract (nn.Module): backbone CNN model.
        pool (nn.Module): type of pooling applied after feature extraction.
        classifier (nn.Module): linear classifier module used to map the features
                                to the output.

    """

    def __init__(self, backbone, nr_input_ch=3, nr_classes=1):
        super().__init__()
        self.nr_classes = nr_classes

        self.feat_extract = get_model(backbone)
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        #! TODO: remove hard-coding of 512 channels below
        self.classifer = nn.Linear(512, nr_classes)

    def forward(self, imgs):
        feat = self.feat_extract(imgs)
        gap_feat = self.pool(feat)
        gap_feat = torch.flatten(gap_feat, 1)
        logit = self.classifer(gap_feat)
        prob = torch.softmax(logit, -1)
        return prob

    @staticmethod
    def infer_batch(model, batch_data):
        """Run inference on an input batch. Contains logic for
        forward operation as well as i/o aggregation.

        Args:
            model (nn.Module): PyTorch defined model.
            batch_data (ndarray): a batch of data generated by torch.utils.data.DataLoader.

        """
        img_patches = batch_data
        img_patches_gpu = img_patches.to("cuda").type(torch.float32)  # to NCHW
        img_patches_gpu = img_patches_gpu.permute(0, 3, 1, 2).contiguous()

        # inference mode
        model.eval()
        # dont compute the gradient (not training)
        with torch.no_grad():
            output = model(img_patches_gpu)
        # output should be a single tensor or scalar
        return output.cpu().numpy()


class CNN_Patch_Predictor(object):
    """Patch-level predictor.

    Attributes:
        batch_size (int): number of images fed into the model each time.
        nr_input_ch (int): number of input channels of the image. If RGB, then this is 3.
        nr_loader_worker (int): number of workers used in torch.utils.data.DataLoader.
        verbose (bool): whether to output logging information.
        model (nn.Module): Defined PyTorch model.

    Usage:
        >>> image_list = np.random.randint(0, 255, [4, 512, 512, 3])
        >>> model = CNN_Patch_Predictor('resnet50', nr_class=8, batch_size=4, nr_loader_workers=4)
        >>> model.predict(image_list)

    """

    def __init__(
        self,
        batch_size,
        model=None,
        backbone="resnet18",
        pretrained="kather",
        nr_input_ch=3,
        nr_loader_worker=0,
        verbose=True,
        *args,
        **kwargs,
    ):
        """Initialise the Patch Predictor. Note, if model is supplied in the arguments, the it
        will override the backbone.

        Args:
            batch_size (int): number of images fed into the model each time.
            model (nn.Module): defined PyTorch model with the define backbone as the feature extractor.
            backbone (str): name of the backbone model. This is obtained from tiatoolbox.models.backbone.
            nr_classes (int): number of classes predicted by the model.
            nr_input_ch (int): number of input channels of the image. If RGB, then this is 3.
            nr_loader_worker (int): number of workers used in torch.utils.data.DataLoader.
            verbose (bool): whether to output logging information.

        """
        super().__init__()
        self.batch_size = batch_size
        self.backbone = backbone
        self.nr_input_ch = nr_input_ch
        self.nr_loader_worker = nr_loader_worker
        self.verbose = verbose

        # get the names and number of class labels
        class_names, nr_classes = dataset_info(pretrained)
        self.class_names = np.array(class_names)

        # get the preprocessing information
        self.preproc_list = preproc_info(pretrained)

        if model is not None:
            self.model = model
        else:
            self.model = CNN_Patch_Model(
                backbone, nr_input_ch=nr_input_ch, nr_classes=nr_classes
            )

        self.load_model(dataset=pretrained)
        return

    def load_model(self, model_path=None, dataset=None, *args, **kwargs):
        """Load model checkpoint either using a supplied model_path or
        by providing a supported dataset name for which the model has been
        trained on.

        Args:
            model_path (pathlib.Path) = path to checkpoint file.
            dataset (str) = name of dataset that the model has been trained on.

        """
        if model_path == None:
            dataset = dataset.lower()
            # download and save model weights
            #! TODO Decide where to dump models - ask Shan
            model_path = "model_weights/%s_%s.pth" % (self.backbone, dataset)
            if not pathlib.Path(model_path).is_file():
                url_root = "https://tiatoolbox.dcs.warwick.ac.uk/models/"
                url_path = "%s%s_%s.pth" % (url_root, backbone, dataset)
                print("Downloading model weights from %s" % url_path)
                r = requests.get(url_path)
                with open(model_path, "wb") as f:
                    f.write(r.content)

        # ! assume to be saved in single GPU mode
        saved_state_dict = torch.load(model_path)
        self.model.load_state_dict(saved_state_dict, strict=True)
        return

    def predict(self, X, return_probs=False, return_names=False, *args, **kwargs):
        """Make a prediction on a list of images or list of paths pointing to images
        of the same shape. Internally, this will create a dataset using 
        tiatoolbox.models.data.classification.Patch_Dataset
        and call predict_dataset.

        Args:
            X(List of :class:`numpy.ndarray` or List of str): a list of numpy.array
            where each is an image or a list of file paths with an extension of
            *.jpg, *.jpeg, *.tif, *.tiff, *.png, *.npy . In either case, all images
            are assumed to be of the same shape.

        Returns:
            output: predictions of the input dataset

        """
        # defer sanity checking to Dataset class, or do it here ?
        ds = Patch_Dataset(X, return_label=False, preproc_list=self.preproc_list)
        output = self.predict_dataset(ds, return_probs, return_names)
        return output

    def predict_dataset(
        self, dataset, return_probs=False, return_names=False, *args, **kwargs
    ):
        """
        Make a prediction on a custom dataset object. Dataset object is Torch compliant.

        # TODO: need check for getitem output form ?
        """

        # TODO preprocessing must be defined with the dataset
        dataloader = torch.utils.data.DataLoader(
            dataset,
            num_workers=self.nr_loader_worker,
            batch_size=self.batch_size,
            drop_last=False,
        )

        # !TODO: need to have a single protocol later for this
        pbar = tqdm.tqdm(
            total=int(len(dataloader)), leave=True, ncols=80, ascii=True, position=0
        )

        # ! may need to take into account CPU/GPU mode
        model = torch.nn.DataParallel(self.model)
        model = model.to("cuda")

        all_output = {}
        preds_output = []
        probs_output = []
        names_output = []
        for batch_idx, batch_input in enumerate(dataloader):
            # calling the static method of that specific ModelDesc
            # on the an instance of ModelDesc, may be there is a nicer way
            # to go about this
            batch_output_probs = self.model.infer_batch(model, batch_input)
            # get the index of the class with the maximum probability
            batch_output = np.argmax(batch_output_probs, axis=-1)
            preds_output.extend(batch_output.tolist())
            if return_probs:
                # return raw output
                probs_output.extend(batch_output_probs.tolist())
            if return_names:
                # return class names
                names_output.extend(self.class_names[batch_output])

            # may be a with block + flag would be nicer
            if self.verbose:
                pbar.update()
        if self.verbose:
            pbar.close()

        pred_output = np.array(preds_output)
        all_output = {"preds": preds_output}
        if return_probs:
            all_output["probs"] = probs_output
        if return_names:
            all_output["names"] = names_output

        return all_output
