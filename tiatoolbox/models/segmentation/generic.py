import math
from collections import OrderedDict

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
from torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence,
                                pad_sequence)

from .resnet_swav import resnet50

def upsample2x(feat):
    return F.interpolate(
        feat, scale_factor=2, mode="bilinear", align_corners=False
    )

def crop_op(x, cropping, data_format="NCHW"):
    """Center crop image
    Args:
        x: input image
        cropping: the substracted amount
        data_format: choose either `NCHW` or `NHWC`
    """
    crop_t = cropping[0] // 2
    crop_b = cropping[0] - crop_t
    crop_l = cropping[1] // 2
    crop_r = cropping[1] - crop_l
    if data_format == "NCHW":
        x = x[:, :, crop_t:-crop_b, crop_l:-crop_r]
    else:
        x = x[:, crop_t:-crop_b, crop_l:-crop_r, :]
    return x
    
####
class UpSample2x(nn.Module):
    """Upsample input by a factor of 2.
    
    Assume input is of NCHW, port FixedUnpooling from TensorPack.
    """

    def __init__(self):
        super(UpSample2x, self).__init__()
        # correct way to create constant within module
        self.register_buffer(
            "unpool_mat", torch.from_numpy(np.ones((2, 2), dtype="float32"))
        )
        self.unpool_mat.unsqueeze(0)

    def forward(self, x):
        input_shape = list(x.shape)
        # unsqueeze is expand_dims equivalent
        # permute is transpose equivalent
        # view is reshape equivalent
        x = x.unsqueeze(-1)  # bchwx1
        mat = self.unpool_mat.unsqueeze(0)  # 1xshxsw
        ret = torch.tensordot(x, mat, dims=1)  # bxcxhxwxshxsw
        ret = ret.permute(0, 1, 2, 4, 3, 5)
        ret = ret.reshape((-1, input_shape[1], input_shape[2] * 2, input_shape[3] * 2))
        return ret


####
class FCN_Model(nn.Module):
    def __init__(self, 
        nr_output_ch=2,
        freeze_encoder=True
    ):
        super().__init__()
        # Normalize over last dimension 
        self.freeze_encoder = freeze_encoder

        # state_dict = torch.load('/root/workspace/projects/tissue_segment/pretrained/'
        #                         'swav_800ep_pretrain.pth.tar')
        # state_dict = {k.replace('module.', '') : v for k, v in state_dict.items()} # to not parallel
        self.backbone = resnet50(output_dim=128, 
                                hidden_mlp=2048, 
                                nmb_prototypes=3000)
        # self.backbone.load_state_dict(state_dict, strict=True)

        self.conv1x1 = nn.Conv2d(2048, 1024, (1, 1), bias=False)

        self.uplist = nn.ModuleList([
            nn.Sequential(
                nn.BatchNorm2d(1024), nn.ReLU(),
                nn.Conv2d(1024, 512, (7, 7), padding=3, bias=False),
            ),
            nn.Sequential(
                nn.BatchNorm2d(512), nn.ReLU(),
                nn.Conv2d(512, 256, (7, 7), padding=3, bias=False),
            ),
            nn.Sequential(
                nn.BatchNorm2d(256), nn.ReLU(),
                nn.Conv2d(256, 64, (7, 7), padding=3, bias=False),
            ),
            nn.Sequential(
                nn.BatchNorm2d(64), nn.ReLU(),
                nn.Conv2d(64, 64, (7, 7), padding=3, bias=False),
            )
        ])

        self.clf = nn.Conv2d(64, nr_output_ch, (1, 1), bias=True)
        self.upsample2x = UpSample2x()
        return

    def forward(self, img_list):
       
        img_list = img_list / 255.0 # scale to 0-1

        x0, x1, x2, x3, x4 = self.backbone(img_list, self.freeze_encoder)
    
        x = self.conv1x1(x4)

        en_list = [x0, x1, x2, x3]

        for idx in [1, 2, 3, 4]:
            y = en_list[-idx]
            x = self.upsample2x(x) + y
            x = self.uplist[idx-1](x)
        output = self.clf(x)
        return output

    @staticmethod
    def infer_batch(model, batch_data, on_gpu):
        """Run inference on an input batch. Contains logic for
        forward operation as well as i/o aggregation.

        Args:
            model (nn.Module): PyTorch defined model.
            # ! TODO: change this to object or sthg, as this only need
            # ! to be in the same API protocol as loader
            batch_data (ndarray): A batch of data generated by
                torch.utils.data.DataLoader.
            on_gpu (bool): Whether to run inference on a GPU.

        """

        ####
        model.eval() # infer mode

        ####
        img_list = batch_data
        
        img_list = img_list.to('cuda').type(torch.float32) 
        img_list = img_list.permute(0, 3, 1, 2) # to NCHW
        
        # --------------------------------------------------------------
        with torch.no_grad(): # dont compute gradient
            logit_list = model(img_list)
            logit_list = logit_list.permute(0, 2, 3, 1) # to NHWC
            prob_list = F.softmax(logit_list, -1)

            prob_list = prob_list.permute(0, 3, 1, 2) # to NCHW
            prob_list = upsample2x(prob_list)
            prob_list = crop_op(prob_list, [512, 512])
            prob_list = prob_list.permute(0, 2, 3, 1) # to NHWC
            # pred_list = torch.argmax(prob_list, dim=-1)

        # * Its up to user to define the protocol to process the raw output per step!
        prob_list = prob_list.cpu().numpy()
        return prob_list