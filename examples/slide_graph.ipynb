{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Preparation code\n"," ## Importing related libraries utilized throughout the notebook"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import copy\n","import json\n","import os\n","import pathlib\n","import random\n","import shutil\n","import sys\n","from collections import OrderedDict\n","from typing import List\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","sys.path.append(\"/home/dang/storage_1/workspace/tiatoolbox\")\n","\n","# ! save_yaml, save_as_json => need same name, need to factor out jsonify\n","from tiatoolbox.utils.misc import save_as_json"]},{"cell_type":"markdown","metadata":{},"source":[" Here we define some quality of life functions that will be frequently reused\n"," throughout the notebook.\n"," - `load_json`: Function to load json from path.\n"," - `rmdir`: Function to remove directory at path.\n"," - `rm_n_mkdir`: Function to remove and then re-create directory at path.\n"," This is utilized in cases we want to have fresh set of output at path.\n"," - `recur_find_ext`: Function to traverse directories under path and return\n"," list of file paths of the extension we want to search for. This is much faster\n"," than using `glob`, escpecially in case the directory hierarchy within path is\n"," complicated and there may be more than 1k files we want to find."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def load_json(path: str):\n","    \"\"\"Helper to load json file.\"\"\"\n","    with open(path, \"r\") as fptr:\n","        json_dict = json.load(fptr)\n","    return json_dict\n","\n","\n","def rmdir(dir_path: str):\n","    \"\"\"Helper function to remove directory.\"\"\"\n","    if os.path.isdir(dir_path):\n","        shutil.rmtree(dir_path)\n","    return\n","\n","\n","def rm_n_mkdir(dir_path: str):\n","    \"\"\"Helper function to remove then re-create directory.\"\"\"\n","    if os.path.isdir(dir_path):\n","        shutil.rmtree(dir_path)\n","    os.makedirs(dir_path)\n","    return\n","\n","\n","def recur_find_ext(root_dir: str, exts: List[str]):\n","    \"\"\"Helper function to recursively get files with extensions.\n","\n","    Recursively find all files in directories end with the `ext`\n","    such as `ext=['.png']` . Much faster than glob if the folder\n","    hierachy is complicated and contain > 1000 files.\n","\n","    Args:\n","        root_dir (str): Root directory for searching.\n","        exts (list): List of extensions to match.\n","\n","    Returns:\n","        List of full paths with matched extension in sorted order.\n","\n","    \"\"\"\n","    assert isinstance(exts, list)\n","    file_path_list = []\n","    for cur_path, dir_list, file_list in os.walk(root_dir):\n","        for file_name in file_list:\n","            file_ext = pathlib.Path(file_name).suffix\n","            if file_ext in exts:\n","                full_path = os.path.join(cur_path, file_name)\n","                file_path_list.append(full_path)\n","    file_path_list.sort()\n","    return file_path_list"]},{"cell_type":"markdown","metadata":{},"source":[" ## Loading affiliated dataset\n"," We start the main part of the note book by defining and loading\n"," the affiliated original data. In this case, they are\n"," - The Whole Slide Images (WSIs), or the paths pointing to them.\n"," - The associated tissue masks if they are available to reduce\n"," our subsequent computation when generatin intermediate results.\n"," - The patient labels, and then the slide labels so to speak for\n"," our task.\n","\n"," In the scope of this notebook, our task is classifying if\n"," a WSI is being HER2 negative or positive. And for this\n"," dataset, HER2 status is provided per patient instead of per slide.\n"," As such, for WSIs coming from the same patient, we assign them the\n"," same label. Besides that, WSIs that do not have labels are also\n"," excluded from subsequent processing.\n","\n"," `ROOT_OUTPUT_DIR`: Root directory to save output under.\n"," `WSI_DIR`: Directory contains WSIs.\n"," `MSK_DIR`: Directory to retrieve corresponding WSI mask. If set to `None`,\n"," the subsequent process will use the default method in the toolbox to obtain\n"," the mask here [@!URL]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["SEED = 5\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","\n","ROOT_OUTPUT_DIR = \"/home/dang/storage_1/workspace/tiatoolbox/local/code/dump/\"\n","WSI_DIR = \"/home/dang/storage_1/dataset/TCGA-LUAD/\"\n","MSK_DIR = None\n","\n","wsi_paths = recur_find_ext(WSI_DIR, [\".svs\", \".ndpi\"])\n","wsi_names = [pathlib.Path(v).stem for v in wsi_paths]\n","msk_paths = None if MSK_DIR is None else [f\"{MSK_DIR}/{v}.png\" for v in wsi_names]\n","assert len(wsi_paths) > 0, \"No files found.\"\n","\n","# !- debug injection, remove later\n","wsi_paths = recur_find_ext(\n","    \"/home/dang/storage_1/workspace/tiatoolbox/local/code/data/resnet\", [\".json\"]\n",")\n","wsi_names = np.array([pathlib.Path(v).stem for v in wsi_paths])\n","# !-\n","\n","CLINICAL_FILE = (\n","    \"/home/dang/storage_1/workspace/tiatoolbox/local/code/TCGA-BRCA-DX_CLINI.csv\"\n",")\n","clinical_df = pd.read_csv(CLINICAL_FILE)\n","\n","patient_uids = clinical_df[\"PATIENT\"].to_numpy()\n","patient_labels = clinical_df[\"HER2FinalStatus\"].to_numpy()\n","\n","patient_labels_ = np.full_like(patient_labels, -1)\n","patient_labels_[patient_labels == \"Positive\"] = 1\n","patient_labels_[patient_labels == \"Negative\"] = 0\n","sel = patient_labels_ >= 0\n","\n","patient_labels = patient_uids[sel]\n","patient_labels = patient_labels_[sel]\n","clinical_info = OrderedDict(list(zip(patient_uids, patient_labels)))\n","\n","# retrieve patient code of each WSI, this is basing TCGA bar codes\n","# https://docs.gdc.cancer.gov/Encyclopedia/pages/TCGA_Barcode/\n","wsi_patient_codes = np.array([\"-\".join(v.split(\"-\")[:3]) for v in wsi_names])\n","wsi_labels = np.array(\n","    [clinical_info[v] if v in clinical_info else np.nan for v in wsi_patient_codes]\n",")"]},{"cell_type":"markdown","metadata":{},"source":[" ## Generate the data split\n"," Now, we start defining how out dataset should be split into training,\n"," validation, and testing set. To that end, we define a new function called\n"," `generate_split`. It will receive paired input of the samples and their labels;\n"," the train, valid, and test percentage; and then return a number of stratified\n"," splits."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","\n","def generate_split(x, y, train, valid, test, num_folds):\n","    \"\"\"Helper to generate stratified splits.\n","\n","    Split `x` and `y` in to N number of `num_folds` sets\n","    of `train`, `valid`, and `test` set in stratified manner.\n","    `train`, `valid`, and `test` are guaranteed to be mutually\n","    exclusive.\n","\n","    Args:\n","        x (list, np.ndarray): List of samples.\n","        y (list, np.ndarray): List of labels, each value is the value\n","            of the sample at the same index in `x`.\n","        train (float): Percentage to be used for training set.\n","        valid (float): Percentage to be used for validation set.\n","        test (float): Percentage to be used for testing set.\n","        num_folds (int): Number of split generated.\n","    Returns:\n","        A list of splits where each is a dictionary of\n","        {\n","            'train': [(sample_A, label_A), (sample_B, label_B), ...],\n","            'valid': [(sample_C, label_C), (sample_D, label_D), ...],\n","            'test' : [(sample_E, label_E), (sample_E, label_E), ...],\n","        }\n","\n","    \"\"\"\n","    assert train + valid + test - 1.0 < 1.0e-10, \"Ratio must be summed up to 1.0 .\"\n","\n","    outer_splitter = StratifiedShuffleSplit(\n","        n_splits=num_folds, train_size=train, test_size=valid + test, random_state=SEED\n","    )\n","    inner_splitter = StratifiedShuffleSplit(\n","        n_splits=1,\n","        train_size=valid / (valid + test),\n","        test_size=test / (valid + test),\n","        random_state=SEED,\n","    )\n","\n","    x = np.array(x)\n","    y = np.array(y)\n","    split_list = []\n","    for train_idx, valid_test_idx in outer_splitter.split(x, y):\n","        train_x = x[train_idx]\n","        train_y = y[train_idx]\n","\n","        # holder for valid_test set\n","        x_ = x[valid_test_idx]\n","        y_ = y[valid_test_idx]\n","\n","        # split valid_test into valid and test set\n","        valid_idx, test_idx = list(inner_splitter.split(x_, y_))[0]\n","        valid_x = x_[valid_idx]\n","        valid_y = y_[valid_idx]\n","\n","        test_x = x_[test_idx]\n","        test_y = y_[test_idx]\n","        # integrity check\n","        assert len(set(train_x).intersection(set(valid_x))) == 0\n","        assert len(set(valid_x).intersection(set(test_x))) == 0\n","        assert len(set(train_x).intersection(set(test_x))) == 0\n","\n","        split_list.append(\n","            {\n","                \"train\": list(zip(train_x, train_y)),\n","                \"valid\": list(zip(valid_x, valid_y)),\n","                \"test\": list(zip(test_x, test_y)),\n","            }\n","        )\n","    return split_list"]},{"cell_type":"markdown","metadata":{},"source":[" Now, we split the data with given ratio.\n","\n"," ![@John] do we want to load cached split also? I think we should"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# !- debug injection, remove later\n","wsi_paths = recur_find_ext(\n","    \"/home/dang/storage_1/workspace/tiatoolbox/local/code/data/resnet\", [\".json\"]\n",")\n","wsi_names = np.array([pathlib.Path(v).stem for v in wsi_paths])\n","# !-\n","\n","NUM_FOLDS = 5\n","TEST_RATIO = 0.2\n","TRAIN_RATIO = 0.8 * 0.9\n","VALID_RATIO = 0.8 * 0.1\n","\n","sel = ~np.isnan(wsi_labels)\n","wsi_labels = wsi_labels[sel]\n","wsi_names = wsi_names[sel]\n","\n","label_df = list(zip(wsi_names, wsi_labels))\n","label_df = pd.DataFrame(label_df, columns=[\"WSI-CODE\", \"LABEL\"])\n","\n","x = np.array(label_df[\"WSI-CODE\"].to_list())\n","y = np.array(label_df[\"LABEL\"].to_list())\n","\n","# this one will be used later several times, take care not to\n","# modify it\n","wsi_codes = label_df[\"WSI-CODE\"].to_list()\n","\n","split_list = generate_split(\n","    x, y,\n","    TRAIN_RATIO, VALID_RATIO, TEST_RATIO,\n","    NUM_FOLDS)"]},{"cell_type":"markdown","metadata":{},"source":[" # Generating graph from WSI\n"," Now that we have define of our sources of data, we move on to transform\n"," them into more usable form. For this work, we will want to have each WSI\n"," represented as a a graph. For our work, each node in the graph corresponds\n"," to one patch within the WSI and is then represented by a set of features.\n"," Here, their representation (or features) can be:\n"," - Deep Neural Network features, such as those obtained from the global average\n"," pooling layer after we apply ResNet50 on the patch.\n"," - Or cell composition, where we [!@Wenqi]\n"," With these node-level representations (or features), we then perform clustering\n"," so that nodes which are close to each other both in feature space and in the 2D\n"," space (i.e the WSI canvas) are assigned into the same cluster."]},{"cell_type":"markdown","metadata":{},"source":[" ## Stain normalization on image patch\n"," Both of deep feature and cell compositions requires analyses on the patches.\n"," In histopathology, we often want to normalize the image patch stain to reduce\n"," as much variation as possible. Here we define the normalizer and the function\n"," to perform such job later in parallel processing manner. Both the target image\n"," and the normalizer here are provided by our toolbox at `tiatoolbox.tools.stainnorm`\n"," and `tiatoolbox.data` . Notice we do not perform stain norm here, however, we will\n"," use them in tandem with other methods in the toolbox to automatically handle that."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from tiatoolbox.data import stainnorm_target\n","from tiatoolbox.tools.stainnorm import get_normaliser\n","\n","target_image = stainnorm_target()\n","stain_normaliser = get_normaliser(\"vahadane\")\n","stain_normaliser.fit(target_image)\n","\n","\n","# ! stainormalizer may crash, do we want to handle them manually\n","# ! or ignore it for now? (np.linalg)\n","def stain_norm_func(img):\n","    return stain_normaliser.transform(img)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def rename_output(file_map_list):\n","    for input_path, output_path in file_map_list:\n","        input_name = pathlib.Path(input_path).stem\n","\n","        output_parent_dir = pathlib.Path(output_path).parent\n","\n","        src_path = pathlib.Path(f'{output_path}.position.npy')\n","        new_path = pathlib.Path(f'{output_parent_dir}/{input_name}.position.npy')\n","        src_path.rename(new_path)\n","\n","        src_path = pathlib.Path(f'{output_path}.features.0.npy')\n","        new_path = pathlib.Path(f'{output_parent_dir}/{input_name}.features.npy')\n","        src_path.rename(new_path)"]},{"cell_type":"markdown","metadata":{},"source":[" ## Deep Feature Extraction\n"," Here, we define the code to use functionalities within the toolbox\n"," for feature extraction. To make it better organized and differentiated\n"," from other parts of the notebook, we package it into the small function\n"," `extract_deep_feature`. Within it we define the config object which define\n"," the shape and magnification of the patch we want to extract. While the patch\n"," can be of arbitrary size and come from different resolutions, we use patch\n"," of 512x512 coming from `mpp=0.25` by default. Additionally, we will use\n"," ResNet50 trained on ImageNet as feature extractor. For more detail on how\n"," to further customize this, you can refer to [URL].\n","\n"," Now, to allow extraction for stain-normalized image patches, we need to\n"," provide our `stain_norm_func` above to the model."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from tiatoolbox.models import FeatureExtractor, IOSegmentorConfig\n","from tiatoolbox.models.architecture import CNNExtractor\n","\n","\n","def extract_deep_feature(save_dir):\n","    ioconfig = IOSegmentorConfig(\n","        input_resolutions=[\n","            {\"units\": \"mpp\", \"resolution\": 0.25},\n","        ],\n","        output_resolutions=[\n","            {\"units\": \"mpp\", \"resolution\": 0.25},\n","        ],\n","        patch_input_shape=[512, 512],\n","        patch_output_shape=[512, 512],\n","        stride_shape=[512, 512],\n","        save_resolution={\"units\": \"mpp\", \"resolution\": 8.0},\n","    )\n","    model = CNNExtractor(\"resnet50\")\n","    # using the stain normalization as pre-processing function\n","    model.preproc_func = stain_norm_func\n","    extractor = FeatureExtractor(\n","        batch_size=16, model=model, num_loader_workers=4)\n","\n","    rmdir(save_dir)\n","    output_map = extractor.predict(\n","        wsi_paths,\n","        msk_paths,\n","        mode=\"wsi\",\n","        ioconfig=ioconfig,\n","        on_gpu=True,\n","        crash_on_exception=True,\n","        save_dir=save_dir,\n","    )\n","    rename_output(output_map)\n","    return"]},{"cell_type":"markdown","metadata":{},"source":[" ## Cell Composition Extraction\n"," In a very similar manner, we define the code for extracting cell\n"," composition in `extract_composition_feature`."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from tiatoolbox.models import NucleusInstanceSegmentor\n","\n","\n","def extract_composition_feature(save_dir):\n","    inst_segmentor = NucleusInstanceSegmentor(\n","        pretrained_model=\"hovernet_fast-pannuke\",\n","        batch_size=16,\n","        num_postproc_workers=2,\n","    )\n","\n","    rmdir(save_dir)\n","    output_map = inst_segmentor.predict(\n","        wsi_paths,\n","        msk_paths,\n","        mode=\"wsi\",\n","        on_gpu=True,\n","        crash_on_exception=True,\n","        save_dir=save_dir,\n","    )\n","    rename_output(output_map)\n","\n","    # [!@Wenqi] Cell composition goes here\n","\n","    return output_map"]},{"cell_type":"markdown","metadata":{},"source":[" As we have defined functions for performing WSI feature extraction,\n"," we now perform the extraction itself. Additionally, we would want to avoid\n"," un-necessarily re-extracting the WSI features as they are computationally\n"," expensive in nature. Here, we differentiate these two use cases via `CACHE_PATH`\n"," variable, if `CACHE_PATH = None`, the extraction is performed and the results is saved\n"," under `WSI_FEATURE_DIR`. For ease of organization, we set the\n"," `WSI_FEATURE_DIR = f'{ROOT_OUTPUT_DIR}/features/'` by default. Otherwise, the paths\n"," to feature files are queried. On the other hand, there is `FEATURE_MODE` variable\n"," which dictate which patch features will be extracted. Here, we support\n"," - `\"cnn\"` : for the deep neural network features.\n"," - `\"composition\"` : for the cell composition features.\n","\n"," Lastly, We also put an assertion check by the end to ensure we have\n"," the same number of output file as the number of sample cases we loaded above."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["FEATURE_MODE = \"cnn\"\n","CACHE_PATH = \"/home/dang/storage_1/workspace/tiatoolbox/local/code/data/resnet/\"\n","WSI_FEATURE_DIR = f\"{ROOT_OUTPUT_DIR}/features/\"\n","\n","# !- debug injection, remove later\n","CACHE_PATH = f\"{ROOT_OUTPUT_DIR}/features/\"\n","WSI_DIR = \"/home/dang/storage_1/dataset/TCGA-LUAD/\"\n","wsi_paths = recur_find_ext(WSI_DIR, [\".svs\", \".ndpi\"])[:2]\n","wsi_names = [pathlib.Path(v).stem for v in wsi_paths]\n","# !-\n","\n","if CACHE_PATH and os.path.exists(CACHE_PATH):\n","    # ! check the extension search\n","    output_list = recur_find_ext(f\"{CACHE_PATH}/\", [\".json\"])\n","elif FEATURE_MODE == \"composition\":\n","    output_list = extract_composition_feature(WSI_FEATURE_DIR)\n","else:\n","    output_list = extract_deep_feature(WSI_FEATURE_DIR)\n","# ! put the assertion back later\n","# assert len(output_list) == len(wsi_names), 'Missing output.'"]},{"cell_type":"markdown","metadata":{},"source":[" ## Binding it all into a graph\n"," Finally, with the patches and their features we have just loaded, we construct the graph\n"," for each WSI using the function provided in our toolbox `tiatoolbox.tools.graph`.\n"," Like above, if we already have the graph extracted, we will only need to load them back\n"," via `CACHE_PATH` instead of wasting time on re-doing the job.\n","\n"," ! [@WENQI, a patch is a node here, but are there other cases? We may need to mention here]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from tiatoolbox.tools.graph import hybrid_clustered_graph\n","\n","\n","def construct_graph(wsi_name, save_path):\n","    \"\"\"Construct graph for one WSI and save to file.\"\"\"\n","    positions = np.load(f\"{WSI_FEATURE_DIR}/{wsi_name}.position.npy\")\n","    features = np.load(f\"{WSI_FEATURE_DIR}/{wsi_name}.features.npy\")\n","    graph_dict = hybrid_clustered_graph(positions[:, :2], features)\n","\n","    # Write a graph to a JSON file\n","    with open(save_path, \"w\") as handle:\n","        graph_dict = {k: v.tolist() for k, v in graph_dict.items()}\n","        json.dump(obj=graph_dict, fp=handle)\n","\n","\n","CACHE_PATH = \"/home/dang/storage_1/workspace/tiatoolbox/local/code/data/resnet/\"\n","GRAPH_DIR = f\"{ROOT_OUTPUT_DIR}/graph/\"\n","\n","# !- debug injection, remove later\n","CACHE_PATH = None\n","GRAPH_DIR = f\"{ROOT_OUTPUT_DIR}/graph/\"\n","# !-\n","\n","if CACHE_PATH and os.path.exists(CACHE_PATH):\n","    GRAPH_DIR = CACHE_PATH  # assignment for follow up loading\n","    graph_paths = recur_find_ext(f\"{CACHE_PATH}/\", [\".json\"])\n","else:\n","    rm_n_mkdir(GRAPH_DIR)\n","    graph_paths = [\n","        construct_graph(v, f\"{GRAPH_DIR}/{v}.json\")\n","        for v in wsi_names\n","    ]\n","# ! put the assertion back later\n","# assert len(graph_paths) == len(wsi_names), 'Missing output.'"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# [markdown]\n","# # The Graph Neural Network\n","# ## The dataset loader\n","# As graph dataset that has yet been supported by the toolbox, we defined their\n","# loading and IO conversion here. The goal of this dataset class is to support\n","# parrallely loading the input concurrently from the running process on GPU.\n","# Commonly, it will also perform data conversion or any other preprocessing if\n","# necessary. In the scope of this notebook, we expose `preproc` argument to receive\n","# the function which will normalize node features."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from torch_geometric.data import Data, Dataset\n","from torch_geometric.loader import DataLoader\n","\n","\n","class SlideGraphDataset(Dataset):\n","    \"\"\"Handling loading graph data from disk.\n","\n","    Args:\n","        info_list (list): A list of `[path, label]` in case of\n","            `mode != \"infer\"`, otherwise it is a list of `path`.\n","            Here, `path` points to file containing the graph structure\n","            saved in `.json` while `label` is the label of the graph.\n","            The format within `.json` is expected to from\n","            `tiatoolbox.tools.graph`.\n","        mode (str): Denoting which data mode the `info_list` is in.\n","        preproc (callable): The prerocessing function for each node\n","            within the graph.\n","\n","    \"\"\"\n","\n","    def __init__(self, info_list, mode=\"train\", preproc=None):\n","        self.info_list = info_list\n","        self.mode = mode\n","        self.preproc = preproc\n","\n","    def __getitem__(self, idx):\n","        info = self.info_list[idx]\n","        if any(v in self.mode for v in ['train', 'valid']):\n","            wsi_code, label = info\n","            # torch.Tensor will create 1-d vector not scalar\n","            label = torch.tensor(label)\n","        else:\n","            wsi_code = info\n","\n","        with open(f\"{GRAPH_DIR}/{wsi_code}.json\", \"r\") as fptr:\n","            graph_dict = json.load(fptr)\n","        graph_dict = {k: np.array(v) for k, v in graph_dict.items()}\n","\n","        if self.preproc is not None:\n","            graph_dict[\"x\"] = self.preproc(graph_dict[\"x\"])\n","\n","        graph_dict = {k: torch.tensor(v) for k, v in graph_dict.items()}\n","        graph = Data(**graph_dict)\n","\n","        if any(v in self.mode for v in ['train', 'valid']):\n","            return dict(graph=graph, label=label)\n","        return dict(graph=graph)\n","\n","    def __len__(self):\n","        return len(self.info_list)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# [markdown]\n","# ## Entire dataset feature normalization\n","# Similarly to how we utilize the stain normalizer, we define the feature\n","# normalizer here. Additionally, as this normalization is derived from the\n","# entire dataset population, we first load all the node features from all\n","# the graphs within our dataset and then training the normalizer. To avoid\n","# redundancy, we can also skip this training step and used an existing normalizer\n","# by setting `CACHE_PATH` to a valid path. By default, normalizer is trained and\n","# saved to `SCALER_PATH`."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import joblib\n","from sklearn.preprocessing import StandardScaler\n","\n","CACHE_PATH = None\n","SCALER_PATH = f\"{ROOT_OUTPUT_DIR}/node_scaler.dat\"\n","\n","# !- debug injection, remove later\n","# CACHE_PATH = None\n","# GRAPH_DIR = f\"{ROOT_OUTPUT_DIR}/graph/\"\n","# SCALER_PATH = f\"{ROOT_OUTPUT_DIR}/node_scaler.dat\"\n","# wsi_codes = recur_find_ext(GRAPH_DIR, ['.json'])\n","# wsi_codes = [pathlib.Path(v).stem for v in wsi_codes]\n","\n","# CACHE_PATH = None\n","# GRAPH_DIR = f\"/home/dang/local/workspace/projects/tiatoolbox/local/code/data/resnet/\"\n","# SCALER_PATH = f\"{ROOT_OUTPUT_DIR}/node_scaler.dat\"\n","# wsi_codes = recur_find_ext(GRAPH_DIR, ['.json'])\n","# wsi_codes = [pathlib.Path(v).stem for v in wsi_codes]\n","\n","CACHE_PATH = '/home/dang/storage_1/workspace/tiatoolbox/local/code/data/node_scaler.dat'\n","# !-\n","\n","if CACHE_PATH and os.path.exists(CACHE_PATH):\n","    SCALER_PATH = CACHE_PATH  # assignment for follow up loading\n","    node_scaler = joblib.load(SCALER_PATH)\n","else:\n","    # ! we need a better way of doing this, will have OOM problem\n","    loader = SlideGraphDataset(wsi_codes, mode=\"infer\")\n","    loader = DataLoader(\n","        loader,\n","        num_workers=8,\n","        batch_size=1,\n","        shuffle=False,\n","        drop_last=False\n","    )\n","    node_features = [\n","        v['graph'].x.numpy() for idx, v in enumerate(tqdm(loader))]\n","    node_features = np.concatenate(node_features, axis=0)\n","    node_scaler = StandardScaler(copy=False)\n","    node_scaler.fit(node_features)\n","    joblib.dump(node_scaler, SCALER_PATH)\n","\n","\n","# we must define the function after training\n","def nodes_preproc_func(node_features):\n","    return node_scaler.transform(node_features)\n","\n","\n","# exit()"]},{"cell_type":"markdown","metadata":{},"source":[" # The Graph Neural Network"]},{"cell_type":"markdown","metadata":{},"source":[" ## The architecture holder"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import BatchNorm1d, Linear, ReLU\n","from torch_geometric.nn import (\n","    EdgeConv,\n","    GINConv,\n","    global_add_pool,\n","    global_max_pool,\n","    global_mean_pool,\n",")\n","\n","\n","class SlideGraphArch(nn.Module):\n","    def __init__(\n","        self,\n","        dim_features,\n","        dim_target,\n","        layers=[6, 6],\n","        pooling=\"max\",\n","        dropout=0.0,\n","        conv=\"GINConv\",\n","        gembed=False,\n","        **kwargs,\n","    ):\n","        super().__init__()\n","        self.dropout = dropout\n","        self.embeddings_dim = layers\n","        self.num_layers = len(self.embeddings_dim)\n","        self.nns = []\n","        self.convs = []\n","        self.linears = []\n","        self.pooling = {\n","            \"max\": global_max_pool,\n","            \"mean\": global_mean_pool,\n","            \"add\": global_add_pool,\n","        }[pooling]\n","        # if True then learn graph embedding for final classification\n","        # (classify pooled node features), otherwise pool node decision scores\n","        self.gembed = gembed\n","\n","        conv_dict = {\"GINConv\": [GINConv, 1], \"EdgeConv\": [EdgeConv, 2]}\n","        if conv not in conv_dict:\n","            raise ValueError(f'Not support `conv=\"{conv}\".')\n","\n","        def create_linear(in_dims, out_dims):\n","            return nn.Sequential(\n","                Linear(in_dims, out_dims), BatchNorm1d(out_dims), ReLU()\n","            )\n","\n","        input_emb_dim = dim_features\n","        out_emb_dim = self.embeddings_dim[0]\n","        self.first_h = create_linear(input_emb_dim, out_emb_dim)\n","        self.linears.append(Linear(out_emb_dim, dim_target))\n","\n","        input_emb_dim = out_emb_dim\n","        for out_emb_dim in self.embeddings_dim[1:]:\n","            ConvClass, alpha = conv_dict[conv]\n","            subnet = create_linear(alpha * input_emb_dim, out_emb_dim)\n","            # ! this variable should be removed after training integrity checking\n","            self.nns.append(subnet)  # <--| as it already within ConvClass\n","            self.convs.append(ConvClass(self.nns[-1], **kwargs))\n","            self.linears.append(Linear(out_emb_dim, dim_target))\n","            input_emb_dim = out_emb_dim\n","\n","        self.nns = torch.nn.ModuleList(self.nns)\n","        self.convs = torch.nn.ModuleList(self.convs)\n","        # has got one more for initial input, what does this mean\n","        self.linears = torch.nn.ModuleList(self.linears)\n","\n","        # auxilary holder for external model, these are saved separately from torch.save\n","        # as they can be sklearn model etc.\n","        self.aux_model = {}\n","\n","    def save(self, path, aux_path):\n","        state_dict = self.state_dict()\n","        torch.save(state_dict, path)\n","        joblib.dump(self.aux_model, aux_path)\n","\n","    def load(self, path, aux_path):\n","        state_dict = torch.load(path)\n","        self.load_state_dict(state_dict)\n","        self.aux_model = joblib.load(aux_path)\n","\n","    def forward(self, data):\n","\n","        feature, edge_index, batch = data.x, data.edge_index, data.batch\n","\n","        wsi_prediction = 0\n","        pooling = self.pooling\n","        node_prediction = 0\n","\n","        feature = self.first_h(feature)\n","        for layer in range(self.num_layers):\n","            if layer == 0:\n","                node_prediction_sub = self.linears[layer](feature)\n","                node_prediction += node_prediction_sub\n","                node_pooled = pooling(node_prediction_sub, batch)\n","                wsi_prediction_sub = F.dropout(\n","                    node_pooled, p=self.dropout, training=self.training\n","                )\n","                wsi_prediction += wsi_prediction_sub\n","            else:\n","                feature = self.convs[layer - 1](feature, edge_index)\n","                if not self.gembed:\n","                    node_prediction_sub = self.linears[layer](feature)\n","                    node_prediction += node_prediction_sub\n","                    node_pooled = pooling(node_prediction_sub, batch)\n","                    wsi_prediction_sub = F.dropout(\n","                        node_pooled, p=self.dropout, training=self.training\n","                    )\n","                else:\n","                    node_pooled = pooling(feature, batch)\n","                    node_prediction_sub = self.linears[layer](node_pooled)\n","                    wsi_prediction_sub = F.dropout(\n","                        node_prediction_sub, p=self.dropout, training=self.training\n","                    )\n","                wsi_prediction += wsi_prediction_sub\n","        return wsi_prediction, node_prediction\n","\n","    # running one single step\n","    @staticmethod\n","    def train_batch(model, batch_data, on_gpu, optimizer: torch.optim.Optimizer):\n","        wsi_graphs = batch_data[\"graph\"].to(\"cuda\")\n","        wsi_labels = batch_data[\"label\"].to(\"cuda\")\n","\n","        # data type conversion\n","        wsi_graphs.x = wsi_graphs.x.type(torch.float32)\n","\n","        # not RNN so does not accumulate\n","        optimizer.zero_grad()\n","\n","        model.train()\n","        wsi_output, _ = model(wsi_graphs)\n","\n","        # both expected to be Nx1\n","        wsi_labels_ = wsi_labels[:, None]\n","        wsi_labels_ = wsi_labels_ - wsi_labels_.T\n","        wsi_output_ = wsi_output - wsi_output.T\n","        diff = wsi_output_[wsi_labels_ > 0]\n","        loss = torch.mean(F.relu(1.0 - diff))\n","        # back prop and update\n","        loss.backward()\n","        optimizer.step()\n","\n","        #\n","        loss = loss.detach().cpu().numpy()\n","        assert not np.isnan(loss)\n","        wsi_labels = wsi_labels.cpu().numpy()\n","        return [loss, wsi_output, wsi_labels]\n","\n","    # running one single step\n","    @staticmethod\n","    def infer_batch(model, batch_data, on_gpu):\n","        wsi_graphs = batch_data[\"graph\"].to(\"cuda\")\n","\n","        # data type conversion\n","        wsi_graphs.x = wsi_graphs.x.type(torch.float32)\n","\n","        # Inference mode\n","        model.eval()\n","        # Do not compute the gradient (not training)\n","        with torch.inference_mode():\n","            wsi_output, _ = model(wsi_graphs)\n","\n","        wsi_output = wsi_output.cpu().numpy()\n","        # Output should be a single tensor or scalar\n","        if \"label\" in batch_data:\n","            wsi_labels = batch_data[\"label\"]\n","            wsi_labels = wsi_labels.cpu().numpy()\n","            return wsi_output, wsi_labels\n","        return [wsi_output]"]},{"cell_type":"markdown","metadata":{},"source":[" To test that our architecture works, at least on the surface level,\n"," we perform a brief inference with some random graph data and print\n"," out the output predictions."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-0.24577929]\n"," [-0.20928249]]\n","[[0.0713252 ]\n"," [0.10816549]]\n"]}],"source":["# !- debug injection, remove later\n","GRAPH_DIR = f\"/home/dang/storage_1/workspace/tiatoolbox/local/code/data/resnet\"\n","SCALER_PATH = f\"{ROOT_OUTPUT_DIR}/node_scaler.dat\"\n","wsi_codes = recur_find_ext(GRAPH_DIR, ['.json'])\n","wsi_codes = [pathlib.Path(v).stem for v in wsi_codes][:2]\n","# !-\n","\n","\n","dummy_ds = SlideGraphDataset(wsi_codes, mode=\"infer\")\n","loader = DataLoader(\n","    dummy_ds,\n","    num_workers=0,\n","    batch_size=8,\n","    shuffle=False,\n",")\n","iterator = iter(loader)\n","batch_data = iterator.__next__()\n","\n","# data type conversion\n","wsi_graphs = batch_data[\"graph\"]\n","wsi_graphs.x = wsi_graphs.x.type(torch.float32)\n","\n","# ! --- [TEST] model forward integerity checking\n","from examples.GNN_modelling import GNN\n","\n","arch_kwargs = dict(\n","    dim_features=2048,\n","    dim_target=1,\n","    layers=[16, 16, 8],\n","    dropout=0.5,\n","    pooling=\"mean\",\n","    conv=\"EdgeConv\",\n","    aggr=\"max\",\n",")\n","pretrained = torch.load(\n","    \"/home/dang/storage_1/workspace/tiatoolbox/local/code/data/wenqi_model.pth\"\n",")\n","src_model = GNN(**arch_kwargs)\n","src_model.load_state_dict(pretrained)\n","\n","dst_model = SlideGraphArch(**arch_kwargs)\n","dst_model.load_state_dict(pretrained)\n","\n","src_model.eval()\n","dst_model.eval()\n","with torch.inference_mode():\n","    src_output, _ = src_model(wsi_graphs)\n","    dst_output, _ = dst_model(wsi_graphs)\n","    src_output = src_output.cpu().numpy()\n","    dst_output = dst_output.cpu().numpy()\n","    assert np.sum(np.abs(src_output - dst_output)) == 0\n","print(src_output)\n","# ! ---\n","\n","# define model object\n","arch_kwargs = dict(\n","    dim_features=2048,\n","    dim_target=1,\n","    layers=[16, 16, 8],\n","    dropout=0.5,\n","    pooling=\"mean\",\n","    conv=\"EdgeConv\",\n","    aggr=\"max\",\n",")\n","model = SlideGraphArch(**arch_kwargs)\n","\n","# inference section\n","model.eval()\n","with torch.inference_mode():\n","    output, _ = model(wsi_graphs)\n","    output = output.cpu().numpy()\n","print(output)"]},{"cell_type":"markdown","metadata":{},"source":[" ## Batch Sampler\n"," Now that we have ensured that the model can run. Let's take a step back and\n"," looking at the model definition again so that we can prepare for the training\n"," and inference handling later.\n","\n"," The `infer_batch` is straigh forward here, it handles inferencing of the input batch\n"," data and organizes the output content. Likewise, `train_batch` defines the handling\n"," for training, such as calculating the loss and so on. For our case, you can realize\n"," that the loss defined here is not straightforward or standardized like the\n"," cross-entropy.There is a pitfall that may crash the training if we do not handle\n"," this:\n"," ```python\n"," wsi_labels_ = wsi_labels[:, None]\n"," wsi_labels_ = wsi_labels_ - wsi_labels_.T\n"," wsi_output_ = wsi_output - wsi_output.T\n"," diff = wsi_output_[wsi_labels_ > 0]\n"," loss = torch.mean(F.relu(1.0 - diff))\n"," ```\n"," Specifically, we need to take care of `diff = wsi_output_[wsi_labels_ > 0]` where\n"," we only want to calculate the loss using pairing containing positive sample. Thus,\n"," when the batch contains no positive samples at all, especially for skewed dataset,\n"," there will no sample to calculate the loss and we will have `NaN` loss. To resolve\n"," this, we define a sampler dedicated for training process such that its resulting\n"," batch will always contain positive samples."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from torch.utils.data import Sampler\n","from sklearn.model_selection import StratifiedKFold\n","\n","\n","class StratifiedSampler(Sampler):\n","    \"\"\"Sampling the dataset such that the batch contains stratified samples.\n","\n","    Args:\n","        labels (list): List of labels, must be in the same ordering as input\n","            samples provided to the `SlideGraphDataset` object.\n","        batch_size (int): Size of the batch.\n","    Returns:\n","        List of indices to query from the `SlideGraphDataset` object.\n","\n","    \"\"\"\n","\n","    def __init__(self, labels, batch_size=10):\n","        self.batch_size = batch_size\n","        self.num_splits = int(len(labels) / self.batch_size)\n","        self.labels = labels\n","        self.num_steps = self.num_splits\n","\n","    def _sampling(self):\n","        # do we want to control randomness here\n","        skf = StratifiedKFold(n_splits=self.num_splits, shuffle=True)\n","        indices = np.arange(len(self.labels))  # idx holder\n","        # return array of arrays of indices in each batch\n","        return [tidx for _, tidx in skf.split(indices, self.labels)]\n","\n","    def __iter__(self):\n","        return iter(self._sampling())\n","\n","    def __len__(self):\n","        \"\"\"The length of the sampler.\n","\n","        This value actually corresponds to the number of steps to query\n","        sampled batch indices. Thus, to maintain epoch and steps hierarchy,\n","        this should be equal to the number of expected steps as in usual\n","        sampling: `steps=dataset_size / batch_size`.\n","\n","        \"\"\"\n","        return self.num_steps"]},{"cell_type":"markdown","metadata":{},"source":[" Here, you can notice the value is not between 0-1. For SlideGraph\n"," approach, we will turn the above values into proper propabilities later\n"," via using the Platt Scaling https://en.wikipedia.org/wiki/Platt_scaling."]},{"cell_type":"markdown","metadata":{},"source":[" ## The running loop\n"," Training and running a neural network at the current time involve wiring\n"," several parts together so that they work in tandem. For training side,\n"," in a simplified term, it consists of:\n"," 1. Define network object from a particular architecture.\n"," 2. Define loader object to handle loading data concurrently.\n"," 3. Define optimizer and scheduler to update network weights.\n"," 4. The callbacks function at several junctions (starting of epoch, end of step, etc.)\n"," to aggregate results, saving the models, refreshing data, and much more.\n","\n"," As for inference side, #3 is not necessary. At the moment, the wiring of these\n"," operations are handled mostly in the toolbox via various `engine` (controller).\n"," However, they focus mostly on inference portion. For SlideGraph case and this\n"," notebook, we also require the training portion. Hence, we define below a very\n"," simplified version of what an `engine` usually do for both `training` and `inference`."]},{"cell_type":"markdown","metadata":{},"source":[" ### Helper functions and classes\n","Helper to clean up progress bar creation.\n"," * changing print char may break the bar so avoid it\n","Object to calculate running average.\n"," calculate the exponential moving average"]},{"cell_type":"markdown","metadata":{},"source":[" ### Defining the loop"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["from tiatoolbox.tools.scale import PlattScaling\n","\n","\n","def run_once(\n","        dataset_dict, num_epochs, save_dir,\n","        on_gpu=True, pretrained=None,\n","        loader_kwargs={}, arch_kwargs={}, optim_kwargs={}):\n","    \"\"\"Running the inference or training loop once.\"\"\"\n","    model = SlideGraphArch(**arch_kwargs)\n","    if pretrained is not None:\n","        model.load(*pretrained)\n","    model = model.to(\"cuda\")\n","    optimizer = torch.optim.Adam(model.parameters(), **optim_kwargs)\n","\n","    # create the graph dataset holder for each subset info then\n","    # pipe them through torch/torch geometric specific loader\n","    # for loading in multi-thread\n","    loader_dict = {}\n","    for subset_name, subset in dataset_dict.items():\n","        _loader_kwargs = copy.deepcopy(loader_kwargs)\n","        batch_sampler = None\n","        if subset_name == 'train':\n","            _loader_kwargs = {}\n","            batch_sampler = StratifiedSampler(\n","                labels=[v[1] for v in subset],\n","                batch_size=loader_kwargs['batch_size']\n","            )\n","\n","        ds = SlideGraphDataset(\n","            subset, mode=subset_name, preproc=nodes_preproc_func)\n","        loader_dict[subset_name] = DataLoader(\n","            ds,\n","            batch_sampler=batch_sampler,\n","            drop_last=subset_name == \"train\" and batch_sampler is None,\n","            shuffle=subset_name == \"train\" and batch_sampler is None,\n","            **_loader_kwargs,\n","        )\n","\n","    for epoch in range(num_epochs):\n","        print(f\"EPOCH {epoch:03d}\")\n","        for loader_name, loader in loader_dict.items():\n","            # * EPOCH START\n","            step_output = []\n","            ema = ScalarMovingAverage()\n","            pbar = create_pbar(loader_name, len(loader))\n","            for step, batch_data in enumerate(loader):\n","                # * STEP COMPLETE CALLBACKS\n","                if loader_name == \"train\":\n","                    output = model.train_batch(model, batch_data, on_gpu, optimizer)\n","                    # check the output for agreement\n","                    ema({\"loss\": output[0]})\n","                    pbar.postfix[1][\"step\"] = output[0]\n","                    pbar.postfix[1][\"EMA\"] = ema.tracking_dict['loss']\n","                else:\n","                    output = model.infer_batch(model, batch_data, on_gpu)\n","                    batch_size = batch_data[\"graph\"].num_graphs\n","                    # iterate over output head and retrieve\n","                    # each as N x item, each item may be of\n","                    # arbitrary dimensions\n","                    output = [np.split(v, batch_size, axis=0) for v in output]\n","                    # pairing such that it will be\n","                    # N batch size x H head list\n","                    output = list(zip(*output))\n","                    step_output.extend(output)\n","                pbar.update()\n","            pbar.close()\n","\n","            # * EPOCH COMPLETE\n","\n","            # callbacks to process output\n","            logging_dict = {}\n","            if loader_name == \"train\":\n","                for val_name, val in ema.tracking_dict.items():\n","                    logging_dict[f\"train-EMA-{val_name}\"] = val\n","            elif (\"infer\" in loader_name and\n","                    any(v in loader_name for v in [\"train\", \"valid\"])):\n","                # expand list of N dataset size x H heads\n","                # back to list of H Head each with N samples\n","                output = list(zip(*step_output))\n","                logit, true = output\n","                logit = np.squeeze(np.array(logit))\n","                true = np.squeeze(np.array(true))\n","\n","                if \"train\" in loader_name:\n","                    scaler = PlattScaling()\n","                    scaler.fit(true, logit)\n","                    model.aux_model['scaler'] = scaler\n","                scaler = model.aux_model['scaler']\n","                prob = scaler.transform(logit)\n","\n","                val = auroc_scorer(true, prob)\n","                logging_dict[f\"{loader_name}-auroc\"] = val\n","                val = auprc_scorer(true, prob)\n","                logging_dict[f\"{loader_name}-auprc\"] = val\n","\n","            # callbacks for logging and saving\n","            for val_name, val in logging_dict.items():\n","                print(f\"{val_name}: {val}\")\n","            if \"train\" not in loader_dict:\n","                continue\n","\n","            # track the statistics\n","            new_stats = {}\n","            if os.path.exists(f\"{save_dir}/stats.json\"):\n","                old_stats = load_json(f\"{save_dir}/stats.json\")\n","                # save a backup first\n","                save_as_json(logging_dict, f\"{save_dir}/stats.old.json\")\n","                new_stats = copy.deepcopy(old_stats)\n","\n","            old_epoch_stats = {}\n","            if epoch in old_epoch_stats:\n","                old_epoch_stats = new_stats[epoch]\n","            old_epoch_stats.update(logging_dict)\n","            new_stats[epoch] = old_epoch_stats\n","            save_as_json(new_stats, f\"{save_dir}/stats.json\")\n","\n","            # save the pytorch model\n","            model.save(\n","                f\"{save_dir}/epoch={epoch:03d}.weights.pth\",\n","                f\"{save_dir}/epoch={epoch:03d}.aux.dat\"\n","            )\n","    return step_output"]},{"cell_type":"markdown","metadata":{},"source":[" ## The training\n"," With the `engine` above, we can now start our training loop with\n"," a set of parameters."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# !- debug injection, remove later\n","GRAPH_DIR = f\"/home/dang/local/workspace/projects/tiatoolbox/local/code/data/resnet/\"\n","SCALER_PATH = f\"{ROOT_OUTPUT_DIR}/node_scaler.dat\"\n","wsi_codes = label_df[\"WSI-CODE\"].to_list()\n","# !-\n","\n","\n","from sklearn.metrics import average_precision_score as auprc_scorer\n","from sklearn.metrics import roc_auc_score as auroc_scorer\n","\n","loader_kwargs = dict(\n","    num_workers=8,\n","    batch_size=16,\n",")\n","arch_kwargs = dict(\n","    dim_features=2048,\n","    dim_target=1,\n","    layers=[16, 16, 8],\n","    dropout=0.5,\n","    pooling=\"mean\",\n","    conv=\"EdgeConv\",\n","    aggr=\"max\",\n",")\n","optim_kwargs = dict(\n","    lr=1.0e-3,\n","    weight_decay=1.0e-4,\n",")\n","NUM_EPOCHS = 5\n","\n","MODEL_DIR = f\"{ROOT_OUTPUT_DIR}/model/\"\n","for split_idx, split in enumerate(split_list):\n","    break\n","    new_split = {\n","        \"train\": split['train'],\n","        \"infer-train\": split['train'],\n","        \"infer-valid\": split['valid']\n","    }\n","    split_save_dir = f\"{MODEL_DIR}/{split_idx:02d}/\"\n","    rm_n_mkdir(split_save_dir)\n","    run_once(\n","        new_split, NUM_EPOCHS,\n","        save_dir=split_save_dir,\n","        arch_kwargs=arch_kwargs,\n","        loader_kwargs=loader_kwargs,\n","        optim_kwargs=optim_kwargs)"]},{"cell_type":"markdown","metadata":{},"source":[" ## The inference"]},{"cell_type":"markdown","metadata":{},"source":[" ### The model selections\n"," According to our engine running loop definition above, these\n"," are the metrics saved for each epoch:\n"," - \"infer-train-auroc\"\n"," - \"infer-train-auprc\"\n"," - \"infer-valid-auroc\"\n"," - \"infer-valid-auprc\""]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["PRETRAINED_DIR = f\"{ROOT_OUTPUT_DIR}/model/\"\n","stat_files = recur_find_ext(PRETRAINED_DIR, [\".json\"])\n","stat_files = [v for v in stat_files if \".old.json\" not in v]\n","\n","\n","def select_checkpoints(\n","        stat_file_path: str,\n","        top_k: int = 2,\n","        metric: str = \"infer-valid-auprc\"):\n","    \"\"\"Select checkpoints basing on training statistics.\n","\n","    Args:\n","        stat_file_path (str): Path pointing to the .json\n","            which contains the statistics.\n","        top_k (int): Number of top checkpoints to be selected.\n","        metric (str): The metric name saved within .json to perform\n","            selection.\n","    Returns:\n","        paths (list): List of paths or info tuple where each point\n","            to the correspond check point saving location.\n","        stats (list): List of corresponding statistics.\n","\n","    \"\"\"\n","    stats_dict = load_json(stat_file_path)\n","    # k is the epoch counter in this case\n","    stats = [[int(k), v[metric]] for k, v in stats_dict.items()]\n","    # sort epoch ranking from largest to smallest\n","    stats = sorted(stats, key=lambda v: v[1], reverse=True)\n","    chkpt_stats_list = stats[:top_k]  # select top_k\n","\n","    model_dir = pathlib.Path(stat_file_path).parent\n","    epochs = [v[0] for v in chkpt_stats_list]\n","    paths = [(\n","        f\"{model_dir}/epoch={epoch:03d}.weights.pth\",\n","        f\"{model_dir}/epoch={epoch:03d}.aux.dat\")\n","        for epoch in epochs\n","    ]\n","    return paths, chkpt_stats_list\n","\n","\n","chkpts, chkpt_stats_list = select_checkpoints(stat_files[0])"]},{"cell_type":"markdown","metadata":{},"source":[" ### Bulk inference and ensemble results"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# !- injecttion debug\n","split_list = split_list[:1]\n","# !-\n","\n","loader_kwargs = dict(\n","    num_workers=8,\n","    batch_size=16,\n",")\n","arch_kwargs = dict(\n","    dim_features=2048,\n","    dim_target=1,\n","    layers=[16, 16, 8],\n","    dropout=0.5,\n","    pooling=\"mean\",\n","    conv=\"EdgeConv\",\n","    aggr=\"max\",\n",")\n","\n","cum_stats = []\n","for split_idx, split in enumerate(split_list):\n","    break\n","    new_split = {\n","        \"infer\": [v[0] for v in split[\"test\"]]\n","    }\n","\n","    # Perform ensembling by averaging probabilities\n","    # across checkpoint predictions\n","    cum_results = []\n","    for chkpt_info in chkpts:\n","        chkpt_results = run_once(\n","            new_split,\n","            num_epochs=1,\n","            save_dir=None,\n","            pretrained=chkpt_info,\n","            arch_kwargs=arch_kwargs,\n","            loader_kwargs=loader_kwargs,\n","        )\n","\n","        # * re-calibrate logit to probabilities\n","        model = SlideGraphArch(**arch_kwargs)\n","        model.load(*chkpt_info)\n","        scaler = model.aux_model['scaler']\n","        chkpt_results = np.array(chkpt_results)\n","        chkpt_results = np.squeeze(chkpt_results)\n","        chkpt_results = scaler.transform(chkpt_results)\n","\n","        cum_results.append(chkpt_results)\n","    cum_results = np.array(cum_results)\n","    cum_results = np.squeeze(cum_results)\n","    prob = np.mean(cum_results, axis=0)\n","\n","    # * calculate split statistics\n","    true = [v[1] for v in split[\"test\"]]\n","    true = np.array(true)\n","\n","    cum_stats.append({\n","        'auroc': auroc_scorer(true, prob),\n","        'auprc': auprc_scorer(true, prob)\n","    })\n","\n","stat_df = pd.DataFrame(cum_stats)\n","for metric in stat_df.columns:\n","    vals = stat_df[metric]\n","    mu = np.mean(vals)\n","    va = np.std(vals)\n","    print(f'{metric}: {mu:0.4f}{va:0.4f}')"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
