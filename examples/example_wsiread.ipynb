{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kag0_9eJLPd"
   },
   "source": [
    "# WSI Reading and Visualisation Example\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/TIA-Lab/tiatoolbox/blob/example-wsiread/examples/example_wsiread.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/TIA-Lab/tiatoolbox/blob/example-wsiread/examples/example_wsiread.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3l08vukKAWo"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkcfpWm_JLPh"
   },
   "source": [
    "*Note*: This notebook assumes that `tiatoolbox` has already been installed. If it isn't, you can install it to your python environment by following guideline from https://github.com/TIA-Lab/tiatoolbox or you can install the stable release by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WyoecokJLPi",
    "outputId": "5fc1a43d-1368-4ff2-d00b-8521ef18c0ce"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "[ -d tmp ] && ( echo \"deleting tmp directory\"; rm -rf tmp )\n",
    "clb=$(env | grep COLAB | wc -c);\n",
    "if [ $clb -gt 0 ]\n",
    "then\n",
    "    echo \"working in colab\"\n",
    "    pl=$(pip list | grep datascience | wc -c)\n",
    "    if [ $pl -gt 0 ]\n",
    "    then\n",
    "        echo \"uninstalling colab packages with conflicts\"\n",
    "        pip uninstall -y datascience\n",
    "        pip uninstall -y albumentations\n",
    "        apt-get -y install libopenjp2-7-dev libopenjp2-tools openslide-tools\n",
    "        pip install tiatoolbox\n",
    "    fi\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZbRZb4gJLPj"
   },
   "source": [
    "Welcome to tiatoolbox. This is an example to read a whole slide image (WSI) using tiatoolbox. We will load a sample whole slide image (WSI), check out some key information, then extract some image patches from it. From this, we will examine `wsireader` and `slide_info` modules of the library.\n",
    "\n",
    "We will start by importing some libraries required to run this notebook examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEIfjUTaJLPj"
   },
   "outputs": [],
   "source": [
    "from tiatoolbox.dataloader import wsireader\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300 # for high resolution figure in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKterRqUKHnW"
   },
   "source": [
    "## Reading in a WSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmJxBFzDJLPj"
   },
   "source": [
    "To start with, we will load a small WSI. This WSI is provided using the path variable  `user_sample_wsi_path`. By default, the value is `None` and the WSI will be downloaded from the web using the provided links instead. When downloading from the web, the WSI will be saved under `data_dir` with the named provided in `sample_file_name`. Additionally, data generated by the notebook will also be stored under `data_dir`. Users should change the `data_dir` to their preferred location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irBRlF2_JLPj"
   },
   "outputs": [],
   "source": [
    "data_dir = './tmp'\n",
    "sample_file_name = 'sample_wsi_small.svs'\n",
    "\n",
    "user_sample_wsi_path = None\n",
    "\n",
    "if user_sample_wsi_path is None:\n",
    "    sample_wsi_path = '%s/%s' % (data_dir, sample_file_name)\n",
    "else:\n",
    "    sample_wsi_path = user_sample_wsi_path\n",
    "if not os.path.exists(sample_wsi_path):\n",
    "    os.mkdir(data_dir)\n",
    "    r = requests.get(\n",
    "        \"http://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/CMU-1-Small-Region.svs\"\n",
    "    )\n",
    "    with open(sample_wsi_path, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFIP6-aeJLPk"
   },
   "source": [
    "Now, we will create an `OpenSlideWSIReader` object to load information from the WSI. For this class, the `input_path` is the path pointing to the WSI, while the `output_dir` gives a directory for storing intermediate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBdUkswmJLPk"
   },
   "outputs": [],
   "source": [
    "# create a file handler\n",
    "wsi_reader = wsireader.get_wsireader(\n",
    "                input_img=sample_wsi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5gAhPRIJLPk"
   },
   "source": [
    "First, let's check the basic WSI information, such as magnification, dimension, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GgniFBEJLPk",
    "outputId": "86cccf6b-ac12-4432-d258-cbbeb0ae5de1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wsi_info = wsi_reader.info.as_dict()\n",
    "# we will print out each info line by line\n",
    "print(*list(wsi_info.items()), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHIvSsgOJLPl"
   },
   "source": [
    "We can also load the WSI thumbnail using the `slide_thumbnail` method of the object. The thumbnail can be loaded with different resolution units. For the units, there are:\n",
    "\n",
    "- `mpp`: microns per pixel\n",
    "- `power`: objective power of the scanner\n",
    "- `level`: the level in within the WSI pyramidal file\n",
    "- `baseline`: pixels per baseline pixel\n",
    "\n",
    "We will load the thumbnail at x1.25 objective power as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "gTMn3EBAJLPl",
    "outputId": "b25df85d-bf2b-4657-9b7c-d23923841309"
   },
   "outputs": [],
   "source": [
    "wsi_thumb = wsi_reader.slide_thumbnail(resolution=1.25, units='power')\n",
    "plt.imshow(wsi_thumb)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STwiiLT_KS5k"
   },
   "source": [
    "## Masking example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgdnGWgpJLPl"
   },
   "source": [
    "Now, we will see how to use the WSI object by implementing a small task:\n",
    "\n",
    "*  Get a set of locations from the tissue areas of the WSI thumbnail.\n",
    "* Visualise patches we got previously then load the patches up for visualization.\n",
    "\n",
    "In order to select only patches within tissue areas, we implement a `simple_get_mask` function to threshold the WSI thumbnail intensity and consequently separate the tissue from the background. Here, we use some extra morphological operations, such as dilation, to refine the output. We often call the area to highlight a specific region in the image a **mask**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "kg7CQ9XrJLPm",
    "outputId": "ca8eab3d-2a9e-4b83-afa0-681ff246f7b7"
   },
   "outputs": [],
   "source": [
    "import math, cv2\n",
    "from skimage import morphology\n",
    "\n",
    "# an example function using intensity thresholding and morphological operations to obtain tissue regions\n",
    "def simple_get_mask(rgb):\n",
    "    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU) # threshold using OTSU method\n",
    "    mask = morphology.remove_small_objects(mask == 0, min_size=100, connectivity=2)\n",
    "    mask = morphology.remove_small_holes(mask, area_threshold=100)\n",
    "    mask = morphology.binary_dilation(mask, morphology.disk(5))\n",
    "    return mask\n",
    "\n",
    "# plot thumbnail along with its tissue mask\n",
    "wsi_thumb_mask = simple_get_mask(wsi_thumb)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(wsi_thumb)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(wsi_thumb_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynRtfhgWKcBW"
   },
   "source": [
    "### Extracting patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg80eVhgJLPm"
   },
   "source": [
    "Now, we can write a function to obtain a set of locations from where to extract the patches within the tissue area. The location is defined as the top left coordinates of the source image, along with its corresponding dimensions (height and width). For computational reasons, this operation is done at the thumbnail level (low resolution) and so we will need to map the patch locations and dimensions to the magnification level that we intend to use for patch extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSgiO400JLPm"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "# get the super-pixels (a.k.a rois) of the tissue area and extract\n",
    "# patches centering those super-pixel (a.k.a rois)\n",
    "lores_mag = 1.25 # the magnification of the thumbnail (lores = low resolution)\n",
    "hires_mag = 20 # the magnification where the patch would be extracted (hires = high resolution)\n",
    "hires_patch_size = 128 # expected output patch size at higher resolution\n",
    "# map the expected patch size at hires to lores\n",
    "lores_patch_size = int(hires_patch_size / (hires_mag / lores_mag))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4wYTz-OJLPm"
   },
   "source": [
    "For this example, we would like to create image patches such that they cover the entire WSI. We will use the super-pixel algorithm *SLIC* from `scikit` to do this. It will split the tissue region into regions of similar size at a low resolution. Then we get the patches which are centred at these regions. We also calculate the expected number of patches that can be obtained with the given size. However, note that the actual number of patches may not be the same as the expected number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fmHMDOSQJLPn",
    "outputId": "259e5974-610d-4066-e209-4c7e482ea56a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_expected_rois = math.ceil(np.sum(wsi_thumb_mask) / (lores_patch_size ** 2))\n",
    "wsi_rois_mask = slic(wsi_thumb,\n",
    "                    mask=wsi_thumb_mask,\n",
    "                    n_segments=nr_expected_rois,\n",
    "                    compactness=1000,\n",
    "                    sigma=1)\n",
    "print('#Actual Patches / #Expected Patches : %d/%d' % (np.unique(wsi_rois_mask).shape[0], nr_expected_rois))\n",
    "\n",
    "lores_rois_center = center_of_mass(wsi_rois_mask,\n",
    "                labels=wsi_rois_mask,\n",
    "                index=np.unique(wsi_rois_mask)[1:])\n",
    "lores_rois_center = np.array(lores_rois_center) # coordinates is Y, X\n",
    "lores_rois_center = lores_rois_center.astype(np.int32)\n",
    "selected_indices = wsi_thumb_mask[lores_rois_center[:,0],lores_rois_center[:,1]]\n",
    "lores_rois_center = lores_rois_center[selected_indices]\n",
    "\n",
    "# show the patches region and their centres of mass\n",
    "plt.imshow(mark_boundaries(wsi_thumb, wsi_rois_mask))\n",
    "plt.scatter(lores_rois_center[:,1], lores_rois_center[:,0], s=2)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLvezD0QJLPn"
   },
   "source": [
    "We then convert the centres of each region to the top-left position of the patches at high resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMKYtn7hJLPo"
   },
   "outputs": [],
   "source": [
    "# convert to top left idx at hires_mag level\n",
    "lores_rois_top_left = (lores_rois_center - (lores_patch_size // 2))\n",
    "hires_rois_top_left = lores_rois_top_left * (hires_mag / lores_mag)\n",
    "hires_rois_top_left = hires_rois_top_left.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUgTFxivJLPo"
   },
   "source": [
    "We will now load some patches for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "GXjym5LNJLPo",
    "outputId": "0279a203-62a7-41f3-f73a-ad53b5288152"
   },
   "outputs": [],
   "source": [
    "nr_viz_patches = 16\n",
    "\n",
    "# for illustration purpose, we only visualise a small number of examples\n",
    "selected_indices = np.random.randint(0, hires_rois_top_left.shape[0], size=(4*nr_viz_patches,))\n",
    "hires_rois_top_left = hires_rois_top_left[selected_indices]\n",
    "\n",
    "patch_list = []\n",
    "for patch_coord in hires_rois_top_left:\n",
    "    patch = wsi_reader.read_region(\n",
    "                location=patch_coord[::-1],\n",
    "                level=0, size=hires_patch_size)\n",
    "    patch_list.append(patch)\n",
    "\n",
    "# plot the first 16\n",
    "sub_patches = np.array(patch_list[:16])\n",
    "sub_patches = np.reshape(sub_patches, (4, 4, hires_patch_size, hires_patch_size, 3))\n",
    "sub_patches = np.transpose(sub_patches, (0, 2, 1, 3, 4))\n",
    "sub_patches = np.reshape(sub_patches, (4 * hires_patch_size, 4 * hires_patch_size, 3))\n",
    "plt.imshow(sub_patches)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PTi0FLQJLPo"
   },
   "source": [
    "Conversely, if you want to extract the entire WSI (including the background), you can use the built-in `save_tiles` functionality of the `WSIReader` object.\n",
    "\n",
    "We start by creating another `WSIReader` object and then save tiles using `save_tiles` function with the keywords `tile_objective_value`, `tile_read_size` and `output_dir`. These correspond to the magnification set for reading patches, their expected width & height and the output destination. For clarity, **tile** refers to very large image patches. For this, tiles are read at 20x objective magnification, each of size 1000x1000, and will be saved at the `tmp` folder within the `run_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJ4S2mDcJLPp",
    "outputId": "ef8c8f01-26bc-47fd-abed-8a3083557f8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a file handler\n",
    "wsi_reader_v2 = wsireader.get_wsireader(\n",
    "                input_img=sample_wsi_path\n",
    "                )\n",
    "wsi_reader_v2.save_tiles(\n",
    "                output_dir=data_dir + '/output/',\n",
    "                tile_objective_value=20,\n",
    "                tile_read_size=(1000, 1000)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YufN4e0qJLPp"
   },
   "source": [
    "Now, we will check the content of the output folder and plot some tiles for visualization. The extracted tiles would be saved under the folder at `{data_dir}/output/{sample_file_name}`. The folder would contain a Output.csv which summarizes the extracted tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBrhbTHnJLPp",
    "outputId": "fd4e7b50-1f33-4b4b-863a-250f0e0ce74a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tile_summary = pd.read_csv('{data_dir}/output/{sample_file_name}/Output.csv'.format(\n",
    "                                data_dir=data_dir, sample_file_name=sample_file_name))\n",
    "print(tile_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZlZd0GuJLPp"
   },
   "source": [
    " We will plot `Tile_20_1000_1000.jpg` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "H5rulYAsJLPp",
    "outputId": "736201d3-7e3d-4d54-988a-5a7cd7051599"
   },
   "outputs": [],
   "source": [
    "sample_tile = cv2.imread('%s/output/%s/%s' % (data_dir, sample_file_name, tile_summary.iloc[4]['Tile_Name']))\n",
    "sample_tile = cv2.cvtColor(sample_tile, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(sample_tile)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmx7WdLrKmLi"
   },
   "source": [
    "## jp2 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI-G4ecKJLPq"
   },
   "source": [
    "The library also provides support for reading WSI in `jp2` format via `OmnyxJP2WSIReader` class. This class has the same interface as the class `OpenSlideWSIReader`. We will briefly illustrate this by downloading a `jp2` WSI from the internet and plot its thumbnail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "TayQ63IJJLPq",
    "outputId": "ccea78b7-c711-4b65-fb41-fccec8f33046",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_wsi_path = '%s/sample_jp2.jp2' % data_dir\n",
    "if not os.path.exists(sample_wsi_path):\n",
    "    r = requests.get(\n",
    "        \"https://warwick.ac.uk/fac/sci/dcs/people/csundo/test2.jp2\"\n",
    "    )\n",
    "    with open(sample_wsi_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "wsi_reader = wsireader.get_wsireader(\n",
    "                input_img=sample_wsi_path)\n",
    "wsi_thumb = wsi_reader.slide_thumbnail(resolution=1.25, units='power')\n",
    "plt.imshow(wsi_thumb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ -d tmp ] && ( echo \"deleting tmp directory\"; rm -rf tmp )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "example_wsiread.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
