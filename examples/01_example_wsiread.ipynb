{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kag0_9eJLPd"
   },
   "source": [
    "# Read and Visualize a WSI\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/TIA-Lab/tiatoolbox/blob/master/examples/01_example_wsiread.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/TIA-Lab/tiatoolbox/blob/master/examples/01_example_wsiread.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "_In order to run this notebook on a Kaggle platform, 1) click on the blue Kaggle badge saying_ Open in Kaggle _2) click on_ Settings _on the right of the Kaggle screen, 3) log in to your Kaggle account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3l08vukKAWo"
   },
   "source": [
    "## About this notebook\n",
    "This jupyter notebook can be run on any computer with a standard browser and no programming language is required. It can run remotely over the Internet, free of charge, thanks to Google Colaboratory or Kaggle. To connect with Colab or Kaggle, click on one of the two blue checkboxes above. Check that \"colab\" appears in the browser address bar after you click on \"Open in Colab\". Familiarize yourself with the drop-down menus near the top of the window. You can edit the notebook during the session, for example substituting your own image files for the image files used in this demo. Experiment by changing the parameters of functions. It is not possible for an ordinary user to permanently change this version of the notebook on either Github or colab, so you cannot inadvertently mess it up. Use the notebook's File Menu if you wish to save your own (changed) notebook.\n",
    "\n",
    "Before running the notebook outside Colab, set up your Python environment, as explained in the \n",
    "[README](https://github.com/TIA-Lab/tiatoolbox/blob/master/README.md#install-python-package) file.\n",
    "### Welcome to tiatoolbox!\n",
    "This demo reads a whole slide image (WSI) using tiatoolbox. We load a sample WSI, gather some key information, and then extract some image patches. We demo our modules\n",
    "`wsireader`[details](https://github.com/TIA-Lab/tiatoolbox/blob/master/tiatoolbox/wsicore/wsireader.py) and\n",
    "`slide_info`[details](https://github.com/TIA-Lab/tiatoolbox/blob/master/tiatoolbox/wsicore/slide_info.py).\n",
    "\n",
    "### First cell in bash\n",
    "The first line of code says that the rest of the cell will be interpreted in bash. The second line removes the directory`tmp`if it exists—a previous run may have created it. The other lines set up a suitable Python environment under Colab. No output is expected if the notebook is either run outside Colab or run under Colab for a second time in the same Colab session.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WyoecokJLPi"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "[ -d tmp ] && ( echo \"deleting tmp directory\"; rm -rf tmp )\n",
    "if [ $(env | grep COLAB | wc -c) -gt 0 ] && [ $( pip list | grep datascience | wc -c) -gt 0 ]\n",
    "then\n",
    "    echo \"uninstalling colab packages with conflicts\"\n",
    "    pip uninstall -y datascience\n",
    "    pip uninstall -y albumentations\n",
    "    apt-get -y install libopenjp2-7-dev libopenjp2-tools openslide-tools\n",
    "    pip install tiatoolbox\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmJxBFzDJLPj"
   },
   "source": [
    "We import some some standard Python modules, and also the Python module`wsireader`(see [details](https://github.com/TIA-Lab/tiatoolbox/blob/master/tiatoolbox/wsicore/wsireader.py)) written by the TIA Centre team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEIfjUTaJLPj"
   },
   "outputs": [],
   "source": [
    "from tiatoolbox.wsicore import wsireader\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 150 # for high resolution figure in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKterRqUKHnW"
   },
   "source": [
    "## Reading in a WSI\n",
    "\n",
    "We load a small WSI, specified with the help of the path variable`user_sample_wsi_path`(default value`None`). Unless this None value is changed, the WSI is downloaded from the web, as seen in the code below, and saved with filename given by the variable`sample_file_name`in the directory given by`data_dir`. Data generated by the notebook is stored under data_dir, providing rapid local access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irBRlF2_JLPj"
   },
   "outputs": [],
   "source": [
    "data_dir = './tmp'\n",
    "sample_file_name = 'sample_wsi_small.svs'\n",
    "\n",
    "user_sample_wsi_path = None\n",
    "\n",
    "if user_sample_wsi_path is None:\n",
    "    sample_wsi_path = '%s/%s' % (data_dir, sample_file_name)\n",
    "else:\n",
    "    sample_wsi_path = user_sample_wsi_path\n",
    "if not os.path.exists(sample_wsi_path):\n",
    "    os.mkdir(data_dir)\n",
    "    r = requests.get(\n",
    "        \" https://tiatoolbox.dcs.warwick.ac.uk/sample_wsis/CMU-1-Small-Region.svs\"\n",
    "    )\n",
    "    with open(sample_wsi_path, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFIP6-aeJLPk"
   },
   "source": [
    "Our code shields the user from the incompatible formats produced by different models of scanners from different vendors. The function`wsireader.get_wsireader`has as input a particular WSI, with a particular image format, and outputs an object`wsi_reader_v1`, whose base class is`WSIreader`, and whose derived class depends on the image format. [See details](https://github.com/TIA-Lab/tiatoolbox/blob/master/tiatoolbox/wsicore/wsireader.py). The reader`wsi_reader_v1`provides important information about the WSI. Member functions obtain pixel- or patch-level information, using format-independent code, as we illustrate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBdUkswmJLPk",
    "outputId": "a18c3710-f954-40f4-8194-07d571feff2c"
   },
   "outputs": [],
   "source": [
    "wsi_reader_v1 = wsireader.get_wsireader(\n",
    "                input_img=sample_wsi_path)\n",
    "print(type(wsi_reader_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5gAhPRIJLPk"
   },
   "source": [
    "First, let's check the basic WSI information, such as magnification, dimension, etc.\n",
    "(`mpp`= microns per pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GgniFBEJLPk",
    "outputId": "4ef9fd90-f05d-41d0-96a3-81373178e082",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wsi_info = wsi_reader_v1.info.as_dict()\n",
    "# Print one item per line\n",
    "print(*list(wsi_info.items()), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHIvSsgOJLPl"
   },
   "source": [
    "### Thumbnail\n",
    "To see a thumbnail of the WSI, we use the`slide_thumbnail`method of`wsi_reader_v1`.\n",
    "We load the thumbnail at $\\times1.25$ objective power as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "gTMn3EBAJLPl",
    "outputId": "7d92dd6c-39f7-4adf-b2b8-27acbc99fc92"
   },
   "outputs": [],
   "source": [
    "wsi_thumb = wsi_reader_v1.slide_thumbnail(resolution=1.25, units='power')\n",
    "plt.imshow(wsi_thumb)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgdnGWgpJLPl"
   },
   "source": [
    "## A Mask\n",
    "\n",
    "Over the next several cells, we will use the WSI object`wsi_thumb`to help \n",
    "create a collection of patches covering the tissue area, with limited overlapping. We want to be able to visualise these patches at the high resolution of the original WSI, but it is computationally more efficient to work as much as possible with the much smaller low resolution thumbnail.\n",
    "\n",
    "The first task is distinguish between tissue and glass (no tissue) in the image. We compute a ***mask***, by which we mean a binary colouring of the pixels to either black=glass or white=tissue. The white area is deliberately made a little larger than than tissue area, as this will be appropriate for our task. Our function`simple_get_mask`binarises the thumbnail on the basis of pixel intensity, using the Otsu method. Morphological operations improve the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "kg7CQ9XrJLPm",
    "outputId": "0a234eed-067b-41df-eff0-aaf9532dae9b"
   },
   "outputs": [],
   "source": [
    "import math, cv2\n",
    "from skimage import morphology\n",
    "\n",
    "# an example function using intensity thresholding and morphological operations to obtain tissue regions\n",
    "def simple_get_mask(rgb):\n",
    "    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU) # threshold using the OTSU method\n",
    "    mask = morphology.remove_small_objects(mask == 0, min_size=100, connectivity=2)\n",
    "    mask = morphology.remove_small_holes(mask, area_threshold=100)\n",
    "    mask = morphology.binary_dilation(mask, morphology.disk(5))\n",
    "    return mask\n",
    "\n",
    "# plot thumbnail (left) with its tissue mask (right)\n",
    "wsi_thumb_mask = simple_get_mask(wsi_thumb)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(wsi_thumb)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(wsi_thumb_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynRtfhgWKcBW"
   },
   "source": [
    "### Extracting patches 1: Superpixels and`SLIC`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg80eVhgJLPm"
   },
   "source": [
    "We wish to extract patches from our WSI. We will construct a set of patches covering the tissue region, without too much overlap. This will be achieved using the *SLIC* algorithm, described [here](https://medium.com/@darshita1405/superpixels-and-slic-6b2d8a6e4f08#:~:text=SLIC%20(Simple%20Linear%20Iterative%20Clustering,proximity%20in%20the%20image%20plane.). Our implementation is`slic`from`skimage`. This program segments the tissue region into disjoint ***superpixels***. A superpixel is, by definition, an irregularly shaped, connected union of pixels with common traits, the traits being chosen according to the problem. In`SLIC`, each superpixel consists of pixels that are near each other in the 2d plane of the image, and are also near (or as near as possible, given the various constraints) to each other in 3d colour space. Pixels cluster according to these traits, while, simultaneously, the program aims for a certain number of superpixels (specified by`nr_expected_superpixels`, one of the arguments to`slic`). The result is a collection of superpixels, each superpixel having approximately the same area. The`numpy`array`wsi_superpixels_mask`, output by`slic`, has the same shape as`wsi_thumb_mask`. The $N$ superpixels are numbered $1,2...N-1,N$. Each low resolution pixel in the $i$-th superpixel corresponds to an entry $i$ in the array, and each pixel that is not in any superpixel corresponds to a zero entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSgiO400JLPm",
    "outputId": "be3f8d84-c882-4098-f9ea-7ed0ad35b76a"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "lores_mag = 1.25 # thumbnail objective power (lores = low resolution)\n",
    "hires_mag = 20 # original WSI objective power (hires = high resolution)\n",
    "hires_patch_size = 128 # 128x128 original WSI pixels\n",
    "# map patch size at hires to lores\n",
    "lores_patch_size = int(hires_patch_size / (hires_mag / lores_mag))\n",
    "nr_expected_superpixels = math.ceil(np.sum(wsi_thumb_mask) / (lores_patch_size ** 2))\n",
    "    \n",
    "wsi_superpixels_mask = slic(wsi_thumb,\n",
    "                    mask=wsi_thumb_mask,\n",
    "                    n_segments=nr_expected_superpixels,\n",
    "                    compactness=1000,\n",
    "                    sigma=1)\n",
    "\n",
    "print('#Actual Patches / #Expected Patches : %d/%d' % (np.unique(wsi_superpixels_mask).shape[0], nr_expected_superpixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4wYTz-OJLPm"
   },
   "source": [
    " \n",
    "In the image below, the position of each superpixel is made clear by marking the boundary in yellow. Each centre (blue dot in the image below) of mass of each superpixel is used as the centre of a new square patch. The algorithm encourages the centres to arrange themselves, where possible, in the pattern of a square grid, usually tilted. The patches are all of the same size, and they cover the tissue area. They may overlap, but the overlap is limited. To locate these centres, we need a coordinate system. The algorithm encourages the centres to arrange themselves roughly in the pattern of a square grid, usually tilted. Instead of the familiar`(x,y)`coordinates, we use`(row,column)`coordinates because our data is held in arrays. The origin is at the top-left of the image, and the first coordinate increases as one moves down. Up to this point, we have worked at low resolution for computational efficiency. But examination of each patch in detail requires the use of high resolution data, and we change coordinates accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "fmHMDOSQJLPn",
    "outputId": "b28bd7ad-72af-45e0-df87-88062bff6f6f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lores_superpixels_center = center_of_mass(wsi_superpixels_mask,\n",
    "                labels=wsi_superpixels_mask,\n",
    "                index=np.unique(wsi_superpixels_mask)[1:]) # omit zeros–they correspond to pixels not in any superpx\n",
    "lores_superpixels_center = np.array(lores_superpixels_center) # coordinates Y,X because 2d-array uses row,col\n",
    "lores_superpixels_center = lores_superpixels_center.astype(np.int32)\n",
    "selected_indices = wsi_thumb_mask[lores_superpixels_center[:,0],lores_superpixels_center[:,1]]\n",
    "lores_superpixels_center = lores_superpixels_center[selected_indices]\n",
    "\n",
    "# show the patches region and their centres of mass\n",
    "plt.imshow(mark_boundaries(wsi_thumb, wsi_superpixels_mask))\n",
    "plt.scatter(lores_superpixels_center[:,1], lores_superpixels_center[:,0], s=2)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLvezD0QJLPn"
   },
   "source": [
    "We then convert the centres of each region to the top-left position of the patches at high resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMKYtn7hJLPo"
   },
   "outputs": [],
   "source": [
    "# convert to top left idx at hires_mag level\n",
    "lores_superpixels_top_left = (lores_superpixels_center - (lores_patch_size // 2))\n",
    "hires_superpixels_top_left = lores_superpixels_top_left * (hires_mag / lores_mag)\n",
    "hires_superpixels_top_left = hires_superpixels_top_left.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUgTFxivJLPo"
   },
   "source": [
    "We will now load some patches for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "GXjym5LNJLPo",
    "outputId": "109ad02b-2c84-4ed1-a4c8-a4a190186556"
   },
   "outputs": [],
   "source": [
    "nr_viz_patches = 16\n",
    "\n",
    "# for illustration purpose, we only visualise a small number of examples\n",
    "selected_indices = np.random.randint(0, hires_superpixels_top_left.shape[0], size=(4*nr_viz_patches,))\n",
    "hires_superpixel_top_left = hires_superpixels_top_left[selected_indices]\n",
    "\n",
    "patch_list = []\n",
    "for patch_coord in hires_superpixels_top_left:\n",
    "    patch = wsi_reader_v1.read_region(\n",
    "                location=patch_coord[::-1],\n",
    "                level=0, size=hires_patch_size)\n",
    "    patch_list.append(patch)\n",
    "\n",
    "# plot the first 16\n",
    "sub_patches = np.array(patch_list[:16])\n",
    "sub_patches = np.reshape(sub_patches, (4, 4, hires_patch_size, hires_patch_size, 3))\n",
    "sub_patches = np.transpose(sub_patches, (0, 2, 1, 3, 4))\n",
    "sub_patches = np.reshape(sub_patches, (4 * hires_patch_size, 4 * hires_patch_size, 3))\n",
    "plt.imshow(sub_patches)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PTi0FLQJLPo"
   },
   "source": [
    "If you want to extract the entire WSI (including the background), you can use the built-in`save_tiles`functionality of the`WSIReader`object.\n",
    "\n",
    "We start by creating another`WSIReader`object and then save tiles using the`save_tiles`function with the keywords`tile_objective_value`,`tile_read_size`and`output_dir`. These correspond to the magnification set for reading patches, their expected width & height and the output destination. The word **tile** refers to a very large image patch. Here, tiles are read at 20x objective magnification, each of size $1000\\times1000$, and will be saved in the`data_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJ4S2mDcJLPp",
    "outputId": "3cd835dc-c666-45ed-e8ea-c0142d166dc1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a file handler\n",
    "wsi_reader_v2 = wsireader.get_wsireader(\n",
    "                input_img=sample_wsi_path\n",
    "                )\n",
    "wsi_reader_v2.save_tiles(\n",
    "                output_dir=data_dir + '/output/',\n",
    "                tile_objective_value=20,\n",
    "                tile_read_size=(1000, 1000)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YufN4e0qJLPp"
   },
   "source": [
    "We check the content of the output folder and visualize some tiles. The extracted tiles are saved in the directory`{data_dir}/output/{sample_file_name}`. The folder contains`Output.csv`summarizing the extracted tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBrhbTHnJLPp",
    "outputId": "3709bc81-cbdf-42fb-e00c-52e599d26f9d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tile_summary = pd.read_csv('{data_dir}/output/{sample_file_name}/Output.csv'.format(\n",
    "                                data_dir=data_dir, sample_file_name=sample_file_name))\n",
    "print(tile_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZlZd0GuJLPp"
   },
   "source": [
    " We plot`Tile_20_1000_1000.jpg`as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "H5rulYAsJLPp",
    "outputId": "aa5ebeec-fad1-4f32-c998-11deed57cd9d"
   },
   "outputs": [],
   "source": [
    "sample_tile = cv2.imread('%s/output/%s/%s' % (data_dir, sample_file_name, tile_summary.iloc[4]['Tile_Name']))\n",
    "sample_tile = cv2.cvtColor(sample_tile, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(sample_tile)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmx7WdLrKmLi"
   },
   "source": [
    "## jp2 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI-G4ecKJLPq"
   },
   "source": [
    "The base class`WSIReader`also contains a derived class for WSIs in`jp2`format (see above for more details).We will briefly illustrate this by downloading a`jp2`WSI from the internet and visualize its thumbnail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "TayQ63IJJLPq",
    "outputId": "92b15e21-a9bc-4e9f-f398-ff84636af3fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_wsi_path = '%s/sample_jp2.jp2' % data_dir\n",
    "if not os.path.exists(sample_wsi_path):\n",
    "    r = requests.get(\n",
    "        \"https://tiatoolbox.dcs.warwick.ac.uk/sample_wsis/test1.jp2\"\n",
    "    )\n",
    "    with open(sample_wsi_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "wsi_reader_v3 = wsireader.get_wsireader(\n",
    "                input_img=sample_wsi_path)\n",
    "print(type(wsi_reader_v3))\n",
    "wsi_thumb = wsi_reader_v3.slide_thumbnail(resolution=1.25, units='power')\n",
    "plt.imshow(wsi_thumb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of example_wsiread.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
